{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #8 (Due 11/06/2019, 11:59pm)\n",
    "## Variational Inference for Bayesian Neural Networks\n",
    "\n",
    "**AM 207: Advanced Scientific Computing**<br>\n",
    "**Instructor: Weiwei Pan**<br>\n",
    "**Fall 2019**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Rylan Schaeffer\n",
    "\n",
    "**Students collaborators:** Dimitris Vamvourellis, Dmitry Vukolov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "**Submission Format:** Use this notebook as a template to complete your homework. Please intersperse text blocks (using Markdown cells) amongst `python` code and results -- format your submission for maximum readability. Your assignments will be graded for correctness as well as clarity of exposition and presentation -- a “right” answer by itself without an explanation or is presented with a difficult to follow format will receive no credit.\n",
    "\n",
    "**Code Check:** Before submitting, you must do a \"Restart and Run All\" under \"Kernel\" in the Jupyter or colab menu. Portions of your submission that contains syntactic or run-time errors will not be graded.\n",
    "\n",
    "**Libraries and packages:** Unless a problems specifically asks you to implement from scratch, you are welcomed to use any `python` library package in the standard Anaconda distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy.stats.multivariate_normal as mvn\n",
    "import autograd.scipy.stats.norm as norm\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description: Bayesian Neural Network Regression\n",
    "In Homework #7, you explored sampling from the posteriors of ***Bayesian neural networks*** using HMC. In Lab #8 you'll explore the extent to which HMC can be inefficient or ineffective for sampling from certain types of posteriors. In this homework, you will study variational approximations of BNN posteriors, especially when compared to the posteriors obtained by sampling (in Homework #7). The data is the same as the one for Homework #7.\n",
    "\n",
    "\n",
    "### Part I: Implement Black-Box Variational Inference with the Reparametrization Trick\n",
    "\n",
    "1. (**BBVI with the Reparametrization Trick**) Implement BBVI with the reparametrization trick for approximating an arbitrary posterior $p(w| \\text{Data})$ by an isotropic Gaussian $\\mathcal{N}(\\mu, \\Sigma)$, where $\\Sigma$ is a diagonal matrix. See Lecture #15 or the example code from [autograd's github repo](https://github.com/HIPS/autograd/blob/master/examples/black_box_svi.py). \n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from Lecture 15\n",
    "def black_box_variational_inference(logprob, D, num_samples):\n",
    "    \"\"\"\n",
    "    Implements http://arxiv.org/abs/1401.0118, and uses the\n",
    "    local reparameterization trick from http://arxiv.org/abs/1506.02557\n",
    "    code taken from:\n",
    "    https://github.com/HIPS/autograd/blob/master/examples/black_box_svi.py\n",
    "    \"\"\"\n",
    "\n",
    "    def unpack_params(params):\n",
    "        # Variational dist is a diagonal Gaussian.\n",
    "        mean, log_std = params[:D], params[D:]\n",
    "        return mean, log_std\n",
    "\n",
    "    def gaussian_entropy(log_std):\n",
    "        return 0.5 * D * (1.0 + np.log(2 * np.pi)) + np.sum(log_std)\n",
    "\n",
    "    rs = npr.RandomState(0)\n",
    "\n",
    "    def variational_objective(params, t):\n",
    "        \"\"\"Provides a stochastic estimate of the variational lower bound.\"\"\"\n",
    "        mean, log_std = unpack_params(params)\n",
    "        samples = rs.randn(num_samples, D) * np.exp(log_std) + mean\n",
    "        lower_bound = gaussian_entropy(log_std) + np.mean(logprob(samples, t))\n",
    "        return -lower_bound\n",
    "\n",
    "    gradient = grad(variational_objective)\n",
    "\n",
    "    return variational_objective, gradient, unpack_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from lecture 15\n",
    "def variational_inference(Sigma_W, y_train, x_train, S, max_iteration, step_size, verbose):\n",
    "    '''implements wrapper for variational inference via bbb for bayesian regression'''\n",
    "    D = Sigma_W.shape[0]\n",
    "    Sigma_W_inv = np.linalg.inv(Sigma_W)\n",
    "    Sigma_W_det = np.linalg.det(Sigma_W)\n",
    "    variational_dim = D\n",
    "\n",
    "    # define the log prior on the model parameters\n",
    "    def log_prior(W):\n",
    "        constant_W = -0.5 * (D * np.log(2 * np.pi) + np.log(Sigma_W_det))\n",
    "        exponential_W = -0.5 * np.diag(np.dot(np.dot(W, Sigma_W_inv), W.T))\n",
    "        log_p_W = constant_W + exponential_W\n",
    "        return log_p_W\n",
    "\n",
    "    # define the log likelihood\n",
    "    def log_lklhd(W):\n",
    "        log_odds = np.matmul(W, x_train) + 10\n",
    "        p = 1 / (1 + np.exp(-log_odds))\n",
    "        log_likelihood = y_train * np.log(p)\n",
    "        return log_likelihood\n",
    "\n",
    "    # define the log joint density\n",
    "    log_density = lambda w, t: log_lklhd(w) + log_prior(w)\n",
    "\n",
    "    # build variational objective.\n",
    "    objective, gradient, unpack_params = black_box_variational_inference(log_density, D, num_samples=S)\n",
    "\n",
    "    def callback(params, t, g):\n",
    "        if verbose:\n",
    "            if verbose:\n",
    "                if t % 250 == 0:\n",
    "                    var_means = params[:D]\n",
    "                    var_variance = np.diag(np.exp(params[D:]) ** 2)\n",
    "                    print(\"Iteration {} lower bound {}; gradient mag: {}\".format(\n",
    "                        t, -objective(params, t), np.linalg.norm(gradient(params, t))))\n",
    "                    print('Variational Mean: ', var_means)\n",
    "                    print('Variational Variances: ', var_variance)\n",
    "    print(\"Optimizing variational parameters...\")\n",
    "    # initialize variational parameters\n",
    "    init_mean = 0 * np.ones(D)\n",
    "    init_log_std = -1 * np.ones(D)\n",
    "    init_var_params = np.concatenate([init_mean, init_log_std])\n",
    "\n",
    "    # perform gradient descent using adam (a type of gradient-based optimizer)\n",
    "    variational_params = adam(gradient, init_var_params, step_size=step_size, num_iters=max_iteration,\n",
    "                              callback=callback)\n",
    "\n",
    "    return variational_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from lecture 15\n",
    "def variational_bernoulli_regression(Sigma_W, x_train, y_train, S=2000, max_iteration=2000, step_size=1e-2,\n",
    "                                     verbose=True):\n",
    "    '''perform bayesian regression: infer posterior, visualize posterior predictive, compute log-likelihood'''\n",
    "\n",
    "    D = Sigma_W.shape[0]\n",
    "\n",
    "    # approximate posterior with mean-field gaussian\n",
    "    variational_params = variational_inference(\n",
    "        Sigma_W=Sigma_W,\n",
    "        y_train=y_train,\n",
    "        x_train=x_train,\n",
    "        S=S,\n",
    "        max_iteration=max_iteration,\n",
    "        step_size=step_size,\n",
    "        verbose=verbose)\n",
    "\n",
    "    # sample from the variational posterior\n",
    "    var_means = variational_params[:D]\n",
    "    var_variance = np.diag(np.exp(variational_params[D:]) ** 2)\n",
    "\n",
    "    return var_means, var_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (**Unit Test**) Check that your implementation is correct by approximating the posterior of the following Bayesian logistic regression model:\n",
    "\\begin{align}\n",
    "w &\\sim \\mathcal{N}(0, 1)\\\\\n",
    "Y^{(n)} &\\sim Ber(\\text{sigm}(wX^{(n)} + 10))\n",
    "\\end{align}\n",
    "  where $w$, $Y^{(n)}$, $X^{(n)}$ are a real scalar valued random variables, and where the data consists of a single observation $(Y=1, X=-20)$.\n",
    "\n",
    "  The true posterior $p(w | Y=1, X=-20)$ should look like the following (i.e. the true posterior is left-skewed):\n",
    "<img src=\"./logistic_posterior.png\" style='height:200px;'>\n",
    "  Your mean-field variational approximation should be a Gaussian with mean -0.321 and standard deviation 0.876 (all approximate).\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_W = np.eye(1)\n",
    "ys = np.array([[1.]])\n",
    "xs = np.array([[-20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing variational parameters...\n",
      "Iteration 0 lower bound -0.9000607591755687; gradient mag: 1.843344191550512\n",
      "Variational Mean:  [0.]\n",
      "Variational Variances:  [[0.13533528]]\n",
      "Iteration 250 lower bound -0.5308554096777611; gradient mag: 0.04342946499575649\n",
      "Variational Mean:  [-0.55278621]\n",
      "Variational Variances:  [[0.3123244]]\n",
      "Iteration 500 lower bound -0.5495332434781084; gradient mag: 0.024267477526000565\n",
      "Variational Mean:  [-0.56220134]\n",
      "Variational Variances:  [[0.29677678]]\n",
      "Iteration 750 lower bound -0.5123105974402793; gradient mag: 0.10105491669518347\n",
      "Variational Mean:  [-0.53714465]\n",
      "Variational Variances:  [[0.30552718]]\n",
      "Iteration 1000 lower bound -0.5076064397016626; gradient mag: 0.08304561811120983\n",
      "Variational Mean:  [-0.56753442]\n",
      "Variational Variances:  [[0.29998762]]\n",
      "Iteration 1250 lower bound -0.5194934970867114; gradient mag: 0.019093999482919944\n",
      "Variational Mean:  [-0.56728798]\n",
      "Variational Variances:  [[0.29148606]]\n",
      "Iteration 1500 lower bound -0.5539681364821437; gradient mag: 0.021034908574081055\n",
      "Variational Mean:  [-0.5707026]\n",
      "Variational Variances:  [[0.29863054]]\n",
      "Iteration 1750 lower bound -0.5098963620858575; gradient mag: 0.13166963442394106\n",
      "Variational Mean:  [-0.55570346]\n",
      "Variational Variances:  [[0.2907907]]\n",
      "Iteration 2000 lower bound -0.520567964484722; gradient mag: 0.043056366842566744\n",
      "Variational Mean:  [-0.57835457]\n",
      "Variational Variances:  [[0.310878]]\n"
     ]
    }
   ],
   "source": [
    "variational_mean, variational_variance = variational_bernoulli_regression(\n",
    "    Sigma_W=Sigma_W,\n",
    "    x_train=xs,\n",
    "    y_train=ys,\n",
    "    S=4000,\n",
    "    max_iteration=2001,\n",
    "    step_size=1e-1,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational Mean:  [-0.58291273]\n",
      "Variational Standard Deviation:  [[0.55142108]]\n"
     ]
    }
   ],
   "source": [
    "print('Variational Mean: ', variational_mean)\n",
    "print('Variational Standard Deviation: ', np.sqrt(variational_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Approximate the Posterior of a Bayesian Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy.stats.multivariate_normal as mvn\n",
    "import autograd.scipy.stats.norm as norm\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward:\n",
    "    def __init__(self, architecture, random=None, weights=None):\n",
    "        self.params = {'H': architecture['width'],\n",
    "                       'L': architecture['hidden_layers'],\n",
    "                       'D_in': architecture['input_dim'],\n",
    "                       'D_out': architecture['output_dim'],\n",
    "                       'activation_type': architecture['activation_fn_type'],\n",
    "                       'activation_params': architecture['activation_fn_params']}\n",
    "\n",
    "        self.D = ((architecture['input_dim'] * architecture['width'] + architecture['width'])\n",
    "                  + (architecture['output_dim'] * architecture['width'] + architecture['output_dim'])\n",
    "                  + (architecture['hidden_layers'] - 1) * (architecture['width'] ** 2 + architecture['width'])\n",
    "                  )\n",
    "\n",
    "        if random is not None:\n",
    "            self.random = random\n",
    "        else:\n",
    "            self.random = np.random.RandomState(0)\n",
    "\n",
    "        self.h = architecture['activation_fn']\n",
    "\n",
    "        if weights is None:\n",
    "            self.weights = self.random.normal(0, 1, size=(1, self.D))\n",
    "        else:\n",
    "            self.weights = weights\n",
    "\n",
    "        self.objective_trace = np.empty((1, 1))\n",
    "        self.weight_trace = np.empty((1, self.D))\n",
    "\n",
    "    def forward(self, weights, x):\n",
    "\n",
    "        ''' Forward pass given weights and input '''\n",
    "        H = self.params['H']\n",
    "        D_in =  self.params['D_in']\n",
    "        D_out = self.params['D_out']\n",
    "\n",
    "        assert weights.shape[1] == self.D\n",
    "\n",
    "        if len(x.shape) == 2:\n",
    "            assert x.shape[0] == D_in\n",
    "            x = x.reshape((1, D_in, -1))\n",
    "        else:\n",
    "            assert x.shape[1] == D_in\n",
    "\n",
    "        weights = weights.T\n",
    "\n",
    "        # input to first hidden layer\n",
    "        W = weights[:H * D_in].T.reshape((-1, H, D_in))\n",
    "        b = weights[H * D_in:H * D_in + H].T.reshape((-1, H, 1))\n",
    "        input = self.h(np.matmul(W, x) + b)\n",
    "        index = H * D_in + H\n",
    "\n",
    "        assert input.shape[1] == H\n",
    "\n",
    "        # additional hidden layers\n",
    "        for _ in range(self.params['L'] - 1):\n",
    "            before = index\n",
    "            W = weights[index:index + H * H].T.reshape((-1, H, H))\n",
    "            index += H * H\n",
    "            b = weights[index:index + H].T.reshape((-1, H, 1))\n",
    "            index += H\n",
    "            output = np.matmul(W, input) + b\n",
    "            input = self.h(output)\n",
    "\n",
    "            assert input.shape[1] == H\n",
    "\n",
    "        # output layer\n",
    "        W = weights[index:index + H * D_out].T.reshape((-1, D_out, H))\n",
    "        b = weights[index + H * D_out:].T.reshape((-1, D_out, 1))\n",
    "        output = np.matmul(W, input) + b\n",
    "        assert output.shape[1] == self.params['D_out']\n",
    "        # output = output.squeeze(1)  # Rylan added\n",
    "        return output\n",
    "\n",
    "    def make_objective(self, x_train, y_train, reg_param=None):\n",
    "        ''' Make objective functions: depending on whether or not you want to apply l2 regularization '''\n",
    "\n",
    "        if reg_param is None:\n",
    "\n",
    "            def objective(W, t):\n",
    "                squared_error = np.linalg.norm(y_train - self.forward(W, x_train), axis=1) ** 2\n",
    "                sum_error = np.sum(squared_error)\n",
    "                return sum_error\n",
    "\n",
    "            return objective, grad(objective)\n",
    "\n",
    "        else:\n",
    "\n",
    "            def objective(W, t):\n",
    "                squared_error = np.linalg.norm(y_train - self.forward(W, x_train), axis=1) ** 2\n",
    "                mean_error = np.mean(squared_error) + reg_param * np.linalg.norm(W)\n",
    "                return mean_error\n",
    "\n",
    "            return objective, grad(objective)\n",
    "\n",
    "    def fit(self, x_train, y_train, params, reg_param=None):\n",
    "        ''' Wrapper for MLE through gradient descent '''\n",
    "        assert x_train.shape[0] == self.params['D_in']\n",
    "        assert y_train.shape[0] == self.params['D_out']\n",
    "\n",
    "        ### make objective function for training\n",
    "        self.objective, self.gradient = self.make_objective(x_train, y_train, reg_param)\n",
    "\n",
    "        ### set up optimization\n",
    "        step_size = 0.01\n",
    "        max_iteration = 5000\n",
    "        check_point = 100\n",
    "        weights_init = self.weights.reshape((1, -1))\n",
    "        mass = None\n",
    "        optimizer = 'adam'\n",
    "        random_restarts = 5\n",
    "\n",
    "        if 'step_size' in params.keys():\n",
    "            step_size = params['step_size']\n",
    "        if 'max_iteration' in params.keys():\n",
    "            max_iteration = params['max_iteration']\n",
    "        if 'check_point' in params.keys():\n",
    "            self.check_point = params['check_point']\n",
    "        if 'init' in params.keys():\n",
    "            weights_init = params['init']\n",
    "        if 'call_back' in params.keys():\n",
    "            call_back = params['call_back']\n",
    "        if 'mass' in params.keys():\n",
    "            mass = params['mass']\n",
    "        if 'optimizer' in params.keys():\n",
    "            optimizer = params['optimizer']\n",
    "        if 'random_restarts' in params.keys():\n",
    "            random_restarts = params['random_restarts']\n",
    "\n",
    "        def call_back(weights, iteration, g):\n",
    "            ''' Actions per optimization step '''\n",
    "            objective = self.objective(weights, iteration)\n",
    "            self.objective_trace = np.vstack((self.objective_trace, objective))\n",
    "            self.weight_trace = np.vstack((self.weight_trace, weights))\n",
    "            if iteration % check_point == 0:\n",
    "                print(\"Iteration {} lower bound {}; gradient mag: {}\".format(iteration, objective, np.linalg.norm(\n",
    "                    self.gradient(weights, iteration))))\n",
    "\n",
    "        ### train with random restarts\n",
    "        optimal_obj = 1e16\n",
    "        optimal_weights = self.weights\n",
    "\n",
    "        for i in range(random_restarts):\n",
    "            if optimizer == 'adam':\n",
    "                adam(self.gradient, weights_init, step_size=step_size, num_iters=max_iteration, callback=call_back)\n",
    "            local_opt = np.min(self.objective_trace[-100:])\n",
    "\n",
    "            if local_opt < optimal_obj:\n",
    "                opt_index = np.argmin(self.objective_trace[-100:])\n",
    "                self.weights = self.weight_trace[-100:][opt_index].reshape((1, -1))\n",
    "            weights_init = self.random.normal(0, 1, size=(1, self.D))\n",
    "\n",
    "        self.objective_trace = self.objective_trace[1:]\n",
    "        self.weight_trace = self.weight_trace[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###define rbf activation function\n",
    "alpha = 1\n",
    "c = 0\n",
    "h = lambda x: np.exp(-alpha * (x - c)**2)\n",
    "\n",
    "###neural network model design choices\n",
    "width = 5\n",
    "hidden_layers = 1\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "architecture = {'width': width,\n",
    "               'hidden_layers': hidden_layers,\n",
    "               'input_dim': input_dim,\n",
    "               'output_dim': output_dim,\n",
    "               'activation_fn_type': 'rbf',\n",
    "               'activation_fn_params': 'c=0, alpha=1',\n",
    "               'activation_fn': h}\n",
    "\n",
    "params = {'step_size':1e-3,\n",
    "          'max_iteration': 6001,\n",
    "          'random_restarts':1,\n",
    "          'check_point':200}\n",
    "\n",
    "#set random state to make the experiments replicable\n",
    "rand_state = 0\n",
    "random = np.random.RandomState(rand_state)\n",
    "\n",
    "#instantiate a Feedforward neural network object\n",
    "nn = Feedforward(architecture, random=random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x         y\n",
      "0 -6.0 -3.380284\n",
      "1 -5.6 -2.892117\n",
      "2 -5.2 -2.690059\n",
      "3 -4.8 -2.040000\n",
      "4 -4.4 -1.399942\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('HW7_data.csv')\n",
    "print(df.head())\n",
    "xs = df['x'].values\n",
    "ys = df['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 lower bound 65.11668053773148; gradient mag: 164.7321094609157\n",
      "Iteration 100 lower bound 52.864360467566954; gradient mag: 56.954586390884565\n",
      "Iteration 200 lower bound 49.42633385370296; gradient mag: 28.31627548203755\n",
      "Iteration 300 lower bound 47.733261895623144; gradient mag: 18.31175187956584\n",
      "Iteration 400 lower bound 46.64774569354082; gradient mag: 13.47755254054697\n",
      "Iteration 500 lower bound 45.886915428058316; gradient mag: 10.503599898310592\n",
      "Iteration 600 lower bound 45.25067576634; gradient mag: 8.654932255566825\n",
      "Iteration 700 lower bound 30.562858257343013; gradient mag: 24.1925753228009\n",
      "Iteration 800 lower bound 26.977925085924852; gradient mag: 20.354176994190933\n",
      "Iteration 900 lower bound 24.278363637665738; gradient mag: 18.77912591689822\n",
      "Iteration 1000 lower bound 22.02986716940495; gradient mag: 17.427416991221943\n",
      "Iteration 1100 lower bound 20.10610040886032; gradient mag: 16.21045518866592\n",
      "Iteration 1200 lower bound 18.434367471681025; gradient mag: 15.092044558814075\n",
      "Iteration 1300 lower bound 16.967826824623163; gradient mag: 14.051620576729906\n",
      "Iteration 1400 lower bound 15.673763205688545; gradient mag: 13.07650688789188\n",
      "Iteration 1500 lower bound 14.527850196693981; gradient mag: 12.15858303432993\n",
      "Iteration 1600 lower bound 13.51104118089244; gradient mag: 11.292691333772902\n",
      "Iteration 1700 lower bound 12.607737627992936; gradient mag: 10.475901826346675\n",
      "Iteration 1800 lower bound 11.804614404003857; gradient mag: 9.707342852428729\n",
      "Iteration 1900 lower bound 11.08977327305976; gradient mag: 8.988599356616401\n",
      "Iteration 2000 lower bound 10.452003162028154; gradient mag: 8.324954075223918\n",
      "Iteration 2100 lower bound 9.879926845203448; gradient mag: 7.728107510229664\n",
      "Iteration 2200 lower bound 9.360728932888751; gradient mag: 7.221146412450928\n",
      "Iteration 2300 lower bound 8.878118698993092; gradient mag: 6.843182251011429\n",
      "Iteration 2400 lower bound 8.410371873546008; gradient mag: 6.627021939587406\n",
      "Iteration 2500 lower bound 7.937214402172411; gradient mag: 6.461888287390539\n",
      "Iteration 2600 lower bound 7.471807925987622; gradient mag: 6.054967192028708\n",
      "Iteration 2700 lower bound 7.048560738747636; gradient mag: 5.623261826592469\n",
      "Iteration 2800 lower bound 6.657649714610486; gradient mag: 5.301596015489052\n",
      "Iteration 2900 lower bound 6.286937924356821; gradient mag: 5.005817266509646\n",
      "Iteration 3000 lower bound 5.932348941430825; gradient mag: 4.738230196194087\n",
      "Iteration 3100 lower bound 5.591133620620948; gradient mag: 4.496972816298515\n",
      "Iteration 3200 lower bound 5.26127545540811; gradient mag: 4.278187646372161\n",
      "Iteration 3300 lower bound 4.941457959341479; gradient mag: 4.078179065269128\n",
      "Iteration 3400 lower bound 4.6310060561160205; gradient mag: 3.8933742950112133\n",
      "Iteration 3500 lower bound 4.329797769584352; gradient mag: 3.7204132445853806\n",
      "Iteration 3600 lower bound 4.038157311705763; gradient mag: 3.556269206709465\n",
      "Iteration 3700 lower bound 3.7567400639178525; gradient mag: 3.398336991338033\n",
      "Iteration 3800 lower bound 3.4864181903710856; gradient mag: 3.2444781370885503\n",
      "Iteration 3900 lower bound 3.2281738180915545; gradient mag: 3.09302784318385\n",
      "Iteration 4000 lower bound 2.983004984081998; gradient mag: 2.9427729212293867\n",
      "Iteration 4100 lower bound 2.7518476624500336; gradient mag: 2.7929113696219288\n",
      "Iteration 4200 lower bound 2.535515098891551; gradient mag: 2.643003494153074\n",
      "Iteration 4300 lower bound 2.3346536991188067; gradient mag: 2.4929221870323546\n",
      "Iteration 4400 lower bound 2.149713314288466; gradient mag: 2.3428066637339215\n",
      "Iteration 4500 lower bound 1.9809292604652133; gradient mag: 2.193020647459896\n",
      "Iteration 4600 lower bound 1.8283137632422362; gradient mag: 2.0441136627500742\n",
      "Iteration 4700 lower bound 1.6916553649649706; gradient mag: 1.896783257659039\n",
      "Iteration 4800 lower bound 1.5705256812596617; gradient mag: 1.7518364695730388\n",
      "Iteration 4900 lower bound 1.464293373837468; gradient mag: 1.6101500586762574\n",
      "Iteration 5000 lower bound 1.372145194334405; gradient mag: 1.472630238301942\n",
      "Iteration 5100 lower bound 1.293113555323543; gradient mag: 1.3401733579691384\n",
      "Iteration 5200 lower bound 1.2261095200674328; gradient mag: 1.2136291284746006\n",
      "Iteration 5300 lower bound 1.1699595835060193; gradient mag: 1.0937676769971116\n",
      "Iteration 5400 lower bound 1.1234442741889101; gradient mag: 0.9812512421063398\n",
      "Iteration 5500 lower bound 1.085336480987702; gradient mag: 0.8766108846616596\n",
      "Iteration 5600 lower bound 1.0544374790480324; gradient mag: 0.7802283270250203\n",
      "Iteration 5700 lower bound 1.0296088526691245; gradient mag: 0.6923229786568087\n",
      "Iteration 5800 lower bound 1.0097988475753614; gradient mag: 0.6129443440319642\n",
      "Iteration 5900 lower bound 0.9940621024101455; gradient mag: 0.5419702880196495\n",
      "Iteration 6000 lower bound 0.9815721882281818; gradient mag: 0.4791119652013911\n"
     ]
    }
   ],
   "source": [
    "# train the netework\n",
    "nn.fit(xs.reshape((1, -1)), ys.reshape((1, -1)), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (**Variational Inference for BNNs**) We will implement the following Bayesian model for the data:\n",
    "\\begin{align}\n",
    "\\mathbf{W} &\\sim \\mathcal{N}(0, 5^2 \\mathbf{I}_{D\\times D})\\\\\n",
    "\\mu^{(n)} &= g_{\\mathbf{W}}(\\mathbf{X}^{(n)})\\\\\n",
    "Y^{(n)} &\\sim \\mathcal{N}(\\mu^{(n)}, 0.5^2)\n",
    "\\end{align}\n",
    "  where $g_{\\mathbf{W}}$ is a neural network with parameters $\\mathbf{W}$ represented as a vector in $\\mathbb{R}^{D}$ with $D$ being the total number of parameters (including biases). Just as in HW #7, use a network with a single hidden layer, 5 hidden nodes and rbf activation function.\n",
    "\n",
    "  Implement the log of the joint distribution in `autograd`'s version of `numpy`, i.e. implement $\\log \\left[p(\\mathbf{W})\\prod_{n=1}^N p(Y^{(n)} |\\mathbf{X}^{(n)} , \\mathbf{W}) \\right]$.\n",
    "  \n",
    "  ***Hint:*** you'll need to write out the log of the various Gaussian pdf's and implement their formulae using `autograd`'s numpy functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the log joint distribution and then drop all terms that do not depend on W:\n",
    "\n",
    "\\begin{align}\n",
    "\\log P(W, Y|X)\n",
    "&= \\log \\big[p(W) \\prod_{n=1}^N p(Y^{(n)} | X^{(n)}, W) \\big]\\\\\n",
    "&= \\log p(W) + \\sum_{n=1}^N \\log p(Y^{(n)} | X^{(n)}, W)\\\\\n",
    "&= -\\frac{1}{2} \\log (2\\pi) - \\frac{1}{2} \\log |\\Sigma| -\\frac{1}{2} W^T (5^2 I)^{-1} W + \\sum_{n=1}^N \\log p(Y^{(n)} | X^{(n)}, W)\\\\\n",
    "&\\propto -\\frac{1}{2} W^T (5^2 I)^{-1} W + \\sum_{n=1}^N \\log p(Y^{(n)} | X^{(n)}, W)\\\\\n",
    "&= -\\frac{1}{2} W^T (5^2 I)^{-1} W + \\sum_{n=1}^N -\\frac{1}{2} \\log (2\\pi) - \\frac{1}{2} \\log |0.5^2| -\\frac{1}{2} (Y^{(n)} - \\mu^{(n)})^T (0.5^2)^{-1} (Y^{(n)} - \\mu^{(n)})\\\\\n",
    "&\\propto -\\frac{1}{2} W^T (5^2 I)^{-1} W + \\sum_{n=1}^N -\\frac{1}{2} (Y^{(n)} - g_W(X^{(n)}))^T (0.5^2)^{-1} (Y^{(n)} - g_W(X^{(n)}))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_joint(W, ys, xs):\n",
    "    term1 = -0.5 * W @ W.T / 25\n",
    "    yhats = nn.forward(W, xs.reshape(1, -1))\n",
    "    diff = (yhats - ys).reshape((-1, 1))  # shape [S*12, 1]\n",
    "    term2 = -0.5 * 4 * diff.T @ diff\n",
    "    return term1 + term2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (**Approximate the Posterior**) Use BBVI with the reparametrization trick to approximate the posterior of the Bayesian neural network with a mean-field Gaussian variational family (i.e. an isotropic Gaussian). Please set learning rate and maximum iteration choices as you see fit!\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from Lecture 15\n",
    "def black_box_variational_inference(logprob, D, num_samples):\n",
    "    \"\"\"\n",
    "    Implements http://arxiv.org/abs/1401.0118, and uses the\n",
    "    local reparameterization trick from http://arxiv.org/abs/1506.02557\n",
    "    code taken from:\n",
    "    https://github.com/HIPS/autograd/blob/master/examples/black_box_svi.py\n",
    "    \"\"\"\n",
    "\n",
    "    def unpack_params(params):\n",
    "        # Variational dist is a diagonal Gaussian.\n",
    "        mean, log_std = params[:D], params[D:]\n",
    "        return mean, log_std\n",
    "\n",
    "    def gaussian_entropy(log_std):\n",
    "        return 0.5 * D * (1.0 + np.log(2 * np.pi)) + np.sum(log_std)\n",
    "\n",
    "    rs = npr.RandomState(0)\n",
    "\n",
    "    def variational_objective(params, t):\n",
    "        \"\"\"Provides a stochastic estimate of the variational lower bound.\"\"\"\n",
    "        mean, log_std = unpack_params(params)\n",
    "        samples = rs.randn(num_samples, D) * np.exp(log_std) + mean\n",
    "        lower_bound = gaussian_entropy(log_std) + np.mean(logprob(samples, t))\n",
    "        return -lower_bound\n",
    "\n",
    "    gradient = grad(variational_objective)\n",
    "\n",
    "    return variational_objective, gradient, unpack_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from lecture 15\n",
    "def variational_nn_inference(Sigma_W, y_train, x_train, S, max_iteration, step_size, verbose):\n",
    "    '''implements wrapper for variational inference via bbb for bayesian regression'''\n",
    "    D = Sigma_W.shape[0]\n",
    "    Sigma_W_inv = np.linalg.inv(Sigma_W)\n",
    "    Sigma_W_det = np.linalg.det(Sigma_W)\n",
    "    variational_dim = D\n",
    "\n",
    "    # define the log prior on the model parameters\n",
    "    #     def log_prior(W):\n",
    "    #         constant_W = -0.5 * (D * np.log(2 * np.pi) + np.log(Sigma_W_det))\n",
    "    #         exponential_W = -0.5 * np.diag(np.dot(np.dot(W, Sigma_W_inv), W.T))\n",
    "    #         log_p_W = constant_W + exponential_W\n",
    "    #         return log_p_W\n",
    "\n",
    "    # define the log likelihood\n",
    "    #     def log_lklhd(W):\n",
    "    #         log_odds = np.matmul(W, x_train) + 10\n",
    "    #         p = 1 / (1 + np.exp(-log_odds))\n",
    "    #         log_likelihood = y_train * np.log(p)\n",
    "    #         return log_likelihood\n",
    "\n",
    "    def log_joint(W, ys, xs):\n",
    "        term1 = -0.5 * W @ W.T / 25\n",
    "        yhats = nn.forward(W, xs.reshape(1, -1))\n",
    "        term2 = -0.5 * 4 * np.square(yhats-ys).sum(0).mean()  # given by Weiwei Pan\n",
    "        return term1 + term2\n",
    "\n",
    "    # define the log joint density\n",
    "    #     log_density = lambda w, t: log_lklhd(w) + log_prior(w)\n",
    "    log_density = lambda w, t: log_joint(w, xs=x_train, ys=y_train)\n",
    "\n",
    "    # build variational objective.\n",
    "    objective, gradient, unpack_params = black_box_variational_inference(log_density, D, num_samples=S)\n",
    "\n",
    "    def callback(params, t, g):\n",
    "        if verbose:\n",
    "            if verbose:\n",
    "                if t % 100 == 0:\n",
    "                    var_means = params[:D]\n",
    "                    var_variance = np.exp(params[D:]) ** 2\n",
    "                    # var_variance = np.diag(np.exp(params[D:]) ** 2)\n",
    "                    print(\"Iteration {} lower bound {}; gradient mag: {}\".format(\n",
    "                        t, -objective(params, t), np.linalg.norm(gradient(params, t))))\n",
    "                    print('Variational Mean: ', var_means)\n",
    "                    print('Variational Variances: ', var_variance)\n",
    "\n",
    "    print(\"Optimizing variational parameters...\")\n",
    "    # initialize variational parameters\n",
    "    init_mean = 0 * np.ones(D)\n",
    "    init_log_std = -1 * np.ones(D)\n",
    "    init_var_params = np.concatenate([init_mean, init_log_std])\n",
    "\n",
    "    # perform gradient descent using adam (a type of gradient-based optimizer)\n",
    "    variational_params = adam(gradient, init_var_params, step_size=step_size, num_iters=max_iteration,\n",
    "                              callback=callback)\n",
    "\n",
    "    return variational_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing variational parameters...\n",
      "Iteration 0 lower bound -41584.59312848022; gradient mag: 10395.301055441883\n",
      "Variational Mean:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Variational Variances:  [0.13533528 0.13533528 0.13533528 0.13533528 0.13533528 0.13533528\n",
      " 0.13533528 0.13533528 0.13533528 0.13533528 0.13533528 0.13533528\n",
      " 0.13533528 0.13533528 0.13533528 0.13533528]\n",
      "Iteration 100 lower bound -27347.73357743928; gradient mag: 9191.282325617627\n",
      "Variational Mean:  [ 0.11511876 -0.32719037 -0.60684883  0.53035057 -0.31341777  0.05721407\n",
      " -1.26715252 -1.0230179   1.1056109  -1.30416755  0.16331821 -0.70176874\n",
      " -0.33945213 -0.43886077 -0.74378072 -0.13426113]\n",
      "Variational Variances:  [0.48730584 0.05031199 0.12630069 0.09993786 0.04507383 0.27347039\n",
      " 0.06869778 0.15245972 0.13150871 0.06352707 0.0372509  0.03854145\n",
      " 0.03896857 0.03962194 0.03770594 0.03096716]\n",
      "Iteration 200 lower bound -4631.26522814292; gradient mag: 2698.5143414640675\n",
      "Variational Mean:  [ 0.10381222 -0.33079532 -0.33010417  0.34233691 -0.332859   -0.55199245\n",
      " -2.1568828  -2.26918005  2.28104434 -2.16217362  0.405771   -1.39022594\n",
      " -0.84543079 -1.0821082  -1.42492516  0.9493978 ]\n",
      "Variational Variances:  [0.02542    0.00448441 0.00587023 0.00506597 0.00435607 0.0417763\n",
      " 0.00630542 0.00972377 0.00750886 0.00647289 0.01431904 0.01421922\n",
      " 0.016941   0.015813   0.01409869 0.01445302]\n",
      "Iteration 300 lower bound -2812.2019916997797; gradient mag: 1944.8428420594544\n",
      "Variational Mean:  [ 0.22906775 -0.40617295 -0.43588836  0.43596635 -0.40801026 -1.707065\n",
      " -2.53233076 -2.7953176   2.76630237 -2.53685759  0.29658329 -1.30896539\n",
      " -0.91953159 -1.0850661  -1.35066073  1.12773387]\n",
      "Variational Variances:  [0.00879246 0.00206785 0.00191742 0.00190065 0.0020569  0.02109676\n",
      " 0.00266089 0.00280738 0.00247648 0.00274531 0.00736067 0.0077556\n",
      " 0.00908616 0.00870371 0.00776484 0.00866617]\n",
      "Iteration 400 lower bound -2318.4809621282297; gradient mag: 549.7789763913772\n",
      "Variational Mean:  [ 0.43585084 -0.44524758 -0.49239876  0.48580468 -0.44873751 -2.71482984\n",
      " -2.69709671 -3.04608221  2.98399909 -2.70140176  0.36406396 -1.22920844\n",
      " -0.96833379 -1.06952195 -1.27460305  1.10665806]\n",
      "Variational Variances:  [0.00497336 0.00138036 0.00106618 0.00115853 0.001378   0.00986853\n",
      " 0.00171155 0.00154409 0.00147735 0.00176687 0.0051574  0.00497399\n",
      " 0.00582742 0.00560742 0.00500181 0.00587093]\n",
      "Iteration 500 lower bound -1954.388111026734; gradient mag: 564.3385923011504\n",
      "Variational Mean:  [ 0.72064195 -0.46355248 -0.51565602  0.5063377  -0.46637928 -3.91514259\n",
      " -2.78928625 -3.18999206  3.10559654 -2.79359571  0.58347907 -1.1503727\n",
      " -0.97437762 -1.02811599 -1.19867079  0.94851659]\n",
      "Variational Variances:  [0.00241108 0.00105073 0.00071181 0.00083139 0.00104685 0.00405987\n",
      " 0.00128625 0.0010641  0.00106306 0.0013331  0.00372003 0.00350284\n",
      " 0.0041347  0.00399874 0.00353781 0.00428449]\n",
      "Iteration 600 lower bound -1561.220546676468; gradient mag: 511.10061221134623\n",
      "Variational Mean:  [ 0.99496541 -0.47540891 -0.53723157  0.52441963 -0.47780277 -5.13631841\n",
      " -2.87302827 -3.30574241  3.20492431 -2.87797295  0.9499848  -1.06790542\n",
      " -0.95894282 -0.9727677  -1.11965966  0.73485837]\n",
      "Variational Variances:  [0.00093819 0.00085199 0.00052397 0.00064784 0.00084629 0.0015509\n",
      " 0.00104738 0.00080596 0.00084944 0.00107856 0.00284068 0.00265893\n",
      " 0.0031481  0.00303943 0.00267805 0.00328628]\n",
      "Iteration 700 lower bound -1406.56052560221; gradient mag: 285.29590661725416\n",
      "Variational Mean:  [ 1.08016411 -0.48806153 -0.56077562  0.54283755 -0.49067775 -5.53316118\n",
      " -2.95958902 -3.41586629  3.30021947 -2.96609374  1.2020706  -0.99644686\n",
      " -0.96498903 -0.93617159 -1.05081292  0.58643114]\n",
      "Variational Variances:  [0.00042388 0.00071959 0.00041004 0.00053211 0.0007118  0.000734\n",
      " 0.00089349 0.00065437 0.00071531 0.00091055 0.0023203  0.00211525\n",
      " 0.00248824 0.00241472 0.00213187 0.00261227]\n",
      "Iteration 800 lower bound -1330.6012507981065; gradient mag: 747.7854365720669\n",
      "Variational Mean:  [ 1.04246251 -0.501686   -0.58274693  0.56025362 -0.50518194 -5.35093141\n",
      " -3.0375059  -3.51125223  3.38275234 -3.04582049  1.31750456 -0.93728045\n",
      " -0.9870964  -0.91616484 -0.99420607  0.4878551 ]\n",
      "Variational Variances:  [0.00024169 0.00062512 0.00033148 0.00045087 0.00061598 0.00044532\n",
      " 0.00078947 0.0005534  0.00062753 0.00080021 0.00194417 0.00173955\n",
      " 0.00202457 0.00197057 0.00175337 0.00213293]\n",
      "Iteration 900 lower bound -1279.8877817432954; gradient mag: 338.0919038105007\n",
      "Variational Mean:  [ 0.9927467  -0.51249693 -0.6006356   0.57406726 -0.51558111 -5.10583514\n",
      " -3.10719353 -3.59295794  3.45427033 -3.11791281  1.41093803 -0.88334651\n",
      " -1.00891298 -0.89798593 -0.9423669   0.39682642]\n",
      "Variational Variances:  [0.00015535 0.00055484 0.00027414 0.00039032 0.0005443  0.00030631\n",
      " 0.00071567 0.00048005 0.00056463 0.00072227 0.00164502 0.00146612\n",
      " 0.0016867  0.00164905 0.0014834  0.00177873]\n",
      "Iteration 1000 lower bound -1239.570325717981; gradient mag: 357.08086380017727\n",
      "Variational Mean:  [ 0.95406865 -0.5199948  -0.61778646  0.58654738 -0.52545343 -4.90757816\n",
      " -3.17242846 -3.66734228  3.51969761 -3.18504256  1.49823158 -0.83286853\n",
      " -1.03167071 -0.88164537 -0.89420514  0.31148254]\n",
      "Variational Variances:  [0.00010744 0.00050046 0.000231   0.00034345 0.00048882 0.0002267\n",
      " 0.00066386 0.00042323 0.00052197 0.00066457 0.00140352 0.00126335\n",
      " 0.00142748 0.00140588 0.0012756  0.00150888]\n",
      "Iteration 1100 lower bound -1210.6657778006352; gradient mag: 469.3496280627609\n",
      "Variational Mean:  [ 0.92342595 -0.52820414 -0.63547213  0.59764216 -0.5336829  -4.75278508\n",
      " -3.23312927 -3.73867803  3.58164182 -3.24878278  1.57652404 -0.78675302\n",
      " -1.05776855 -0.86917463 -0.849636    0.23471649]\n",
      "Variational Variances:  [7.82002974e-05 4.57067715e-04 1.96936771e-04 3.05902673e-04\n",
      " 4.44220734e-04 1.77403306e-04 6.27447194e-04 3.78234023e-04\n",
      " 4.89768178e-04 6.22000305e-04 1.20927986e-03 1.10911861e-03\n",
      " 1.22757713e-03 1.21819380e-03 1.11562809e-03 1.29707998e-03]\n",
      "Iteration 1200 lower bound -1187.2275607933946; gradient mag: 476.7638150970339\n",
      "Variational Mean:  [ 0.89922723 -0.53257558 -0.65346781  0.60706061 -0.53867226 -4.62996008\n",
      " -3.29034301 -3.80873964  3.64003405 -3.30884984  1.64615429 -0.74399796\n",
      " -1.08894974 -0.86029948 -0.80904194  0.16732893]\n",
      "Variational Variances:  [5.92388405e-05 4.21308772e-04 1.69592905e-04 2.74864458e-04\n",
      " 4.07701885e-04 1.43985317e-04 6.01869173e-04 3.40351714e-04\n",
      " 4.63130673e-04 5.91592401e-04 1.05253256e-03 9.86843210e-04\n",
      " 1.06538645e-03 1.06781762e-03 9.92710364e-04 1.12713398e-03]\n",
      "Iteration 1300 lower bound -1169.9030717629607; gradient mag: 350.13204317467785\n",
      "Variational Mean:  [ 0.87817443 -0.53496958 -0.67174502  0.61455298 -0.54253437 -4.53257711\n",
      " -3.34260676 -3.87975033  3.69345565 -3.36392365  1.70657342 -0.70514302\n",
      " -1.1260896  -0.85581556 -0.77248876  0.10840649]\n",
      "Variational Variances:  [4.62833702e-05 3.91230518e-04 1.46959706e-04 2.48546990e-04\n",
      " 3.77052319e-04 1.20815092e-04 5.83590413e-04 3.12344997e-04\n",
      " 4.42204644e-04 5.68463641e-04 9.23785617e-04 8.90687348e-04\n",
      " 9.34243124e-04 9.50139909e-04 8.93850109e-04 9.89608695e-04]\n",
      "Iteration 1400 lower bound -1156.684715962296; gradient mag: 316.9194220879685\n",
      "Variational Mean:  [ 0.86192256 -0.53471526 -0.69536522  0.61587172 -0.54520008 -4.45278624\n",
      " -3.39018495 -3.95451228  3.74180146 -3.41405786  1.7590978  -0.6722152\n",
      " -1.17319615 -0.85831549 -0.74142097  0.0569661 ]\n",
      "Variational Variances:  [3.70901983e-05 3.65397291e-04 1.27708749e-04 2.25310147e-04\n",
      " 3.50722746e-04 1.04370237e-04 5.72753050e-04 2.85553236e-04\n",
      " 4.26917330e-04 5.51366493e-04 8.17556023e-04 8.16525569e-04\n",
      " 8.25793604e-04 8.56496696e-04 8.17297183e-04 8.75530549e-04]\n",
      "Iteration 1500 lower bound -1147.4272794902724; gradient mag: 487.5679535514858\n",
      "Variational Mean:  [ 0.85061502 -0.5327795  -0.72154453  0.61206086 -0.54423146 -4.38515108\n",
      " -3.43398656 -4.04470949  3.78466475 -3.46111485  1.80527699 -0.64800298\n",
      " -1.23720452 -0.8737585  -0.71825184  0.01233257]\n",
      "Variational Variances:  [3.03788537e-05 3.42364585e-04 1.10469084e-04 2.03773629e-04\n",
      " 3.27187540e-04 9.24135734e-05 5.65292723e-04 2.57175165e-04\n",
      " 4.09413418e-04 5.39275901e-04 7.29210964e-04 7.58083237e-04\n",
      " 7.34550704e-04 7.82338556e-04 7.56238531e-04 7.79908828e-04]\n",
      "Iteration 1600 lower bound -1134.289011210917; gradient mag: 119.12333784042201\n",
      "Variational Mean:  [ 0.83863314 -0.52896516 -0.75093209  0.60167436 -0.5407194  -4.33151471\n",
      " -3.475408   -4.15419602  3.82442594 -3.50539366  1.84526126 -0.63273588\n",
      " -1.31628404 -0.90141164 -0.70300253 -0.02613859]\n",
      "Variational Variances:  [2.53458806e-05 3.21314769e-04 9.47135070e-05 1.82720296e-04\n",
      " 3.05599465e-04 8.32607957e-05 5.60662707e-04 2.29959780e-04\n",
      " 3.89647186e-04 5.28741300e-04 6.55443676e-04 7.14037371e-04\n",
      " 6.58436399e-04 7.28023313e-04 7.09312086e-04 6.99506333e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1700 lower bound -1125.8822717163778; gradient mag: 294.754781831957\n",
      "Variational Mean:  [ 0.82934251 -0.52328143 -0.77997289  0.59057736 -0.53385866 -4.28471339\n",
      " -3.51606169 -4.27430165  3.8643902  -3.5484903   1.88072406 -0.62781934\n",
      " -1.40556915 -0.9474666  -0.69714892 -0.06041382]\n",
      "Variational Variances:  [2.14873066e-05 3.01435982e-04 8.02773863e-05 1.61875754e-04\n",
      " 2.85188928e-04 7.64056628e-05 5.57587995e-04 2.01775441e-04\n",
      " 3.67616549e-04 5.20289689e-04 5.93094467e-04 6.80989842e-04\n",
      " 5.95081878e-04 6.90673790e-04 6.74788744e-04 6.30986095e-04]\n",
      "Iteration 1800 lower bound -1116.5778770693364; gradient mag: 381.0533994061984\n",
      "Variational Mean:  [ 0.82135311 -0.51722032 -0.80626527  0.58324202 -0.52630944 -4.24401428\n",
      " -3.55654593 -4.38591021  3.90910723 -3.5909594   1.91204013 -0.63302974\n",
      " -1.4883321  -1.0120479  -0.69999842 -0.09154183]\n",
      "Variational Variances:  [1.84380658e-05 2.82572437e-04 6.74305076e-05 1.41571580e-04\n",
      " 2.65769339e-04 7.12437645e-05 5.56322318e-04 1.75398728e-04\n",
      " 3.41166817e-04 5.12654987e-04 5.40320413e-04 6.58056382e-04\n",
      " 5.42207269e-04 6.66529693e-04 6.50738776e-04 5.71776138e-04]\n",
      "Iteration 1900 lower bound -1107.7609465404937; gradient mag: 257.29627668104496\n",
      "Variational Mean:  [ 0.81533694 -0.51299582 -0.8269439   0.58200484 -0.52123429 -4.20913443\n",
      " -3.59804739 -4.47886266  3.96240456 -3.63382876  1.93915747 -0.64435948\n",
      " -1.54574782 -1.09230785 -0.70960289 -0.11803253]\n",
      "Variational Variances:  [1.60042585e-05 2.64364468e-04 5.65771202e-05 1.22334697e-04\n",
      " 2.47450241e-04 6.69109518e-05 5.55085626e-04 1.53130744e-04\n",
      " 3.10991685e-04 5.05581164e-04 4.94878521e-04 6.44141121e-04\n",
      " 4.98130128e-04 6.51868272e-04 6.36719705e-04 5.20713847e-04]\n",
      "Iteration 2000 lower bound -1100.2770510202276; gradient mag: 134.60014824957446\n",
      "Variational Mean:  [ 0.81001593 -0.51130561 -0.84472752  0.5851643  -0.51910862 -4.18436581\n",
      " -3.64175716 -4.56031089  4.02734237 -3.67877359  1.95919299 -0.66150723\n",
      " -1.56789354 -1.18888212 -0.72513606 -0.1377502 ]\n",
      "Variational Variances:  [1.40344744e-05 2.47179638e-04 4.78494956e-05 1.04830787e-04\n",
      " 2.30398852e-04 6.36906699e-05 5.54338620e-04 1.35789792e-04\n",
      " 2.78911235e-04 4.99786879e-04 4.55310943e-04 6.37361951e-04\n",
      " 4.60719505e-04 6.42763583e-04 6.30263300e-04 4.75941985e-04]\n",
      "Iteration 2100 lower bound -1092.2435866800881; gradient mag: 109.52248555576392\n",
      "Variational Mean:  [ 0.8070283  -0.51393795 -0.86780872  0.59430863 -0.52194757 -4.16867281\n",
      " -3.68868511 -4.64596486  4.10536571 -3.72682166  1.97159809 -0.68420429\n",
      " -1.55008239 -1.30402198 -0.7460481  -0.14968989]\n",
      "Variational Variances:  [1.24282730e-05 2.30783654e-04 4.10079279e-05 8.90319308e-05\n",
      " 2.14307124e-04 6.13335971e-05 5.52239015e-04 1.23707082e-04\n",
      " 2.46670388e-04 4.94068160e-04 4.21263984e-04 6.34557844e-04\n",
      " 4.28229106e-04 6.37896804e-04 6.27714489e-04 4.36678180e-04]\n",
      "Iteration 2200 lower bound -1082.0564508370028; gradient mag: 110.65777605648002\n",
      "Variational Mean:  [ 0.80592057 -0.52160677 -0.89957466  0.6096543  -0.52977898 -4.16261157\n",
      " -3.74076168 -4.76310608  4.20033134 -3.78002785  1.97591665 -0.71417196\n",
      " -1.48776078 -1.44392207 -0.77453095 -0.15372124]\n",
      "Variational Variances:  [1.11077347e-05 2.14867337e-04 3.57501997e-05 7.47866101e-05\n",
      " 1.98965811e-04 5.96703973e-05 5.46981167e-04 1.16526693e-04\n",
      " 2.14456913e-04 4.86688024e-04 3.91699926e-04 6.34375040e-04\n",
      " 4.00905225e-04 6.35296421e-04 6.27123977e-04 4.01782274e-04]\n",
      "Iteration 2300 lower bound -1067.621957629299; gradient mag: 511.4302314354824\n",
      "Variational Mean:  [ 0.80649353 -0.53484626 -0.95212881  0.63380865 -0.54339851 -4.16714391\n",
      " -3.80089284 -4.95312341  4.31542306 -3.84115069  1.97136072 -0.75336795\n",
      " -1.38050397 -1.61646779 -0.81223157 -0.14959694]\n",
      "Variational Variances:  [1.00161884e-05 1.99003916e-04 3.17787051e-05 6.19782326e-05\n",
      " 1.83928533e-04 5.86262483e-05 5.35132192e-04 1.14075656e-04\n",
      " 1.80950305e-04 4.74960454e-04 3.65922971e-04 6.34475741e-04\n",
      " 3.77627322e-04 6.32357846e-04 6.26564768e-04 3.71073668e-04]\n",
      "Iteration 2400 lower bound -1045.4998985206828; gradient mag: 690.8241754433332\n",
      "Variational Mean:  [ 0.80941884 -0.54865348 -1.03690813  0.66107404 -0.55798588 -4.18016224\n",
      " -3.86999068 -5.2688519   4.44595092 -3.91096392  1.95970527 -0.79421538\n",
      " -1.26944746 -1.80978824 -0.85250186 -0.13832111]\n",
      "Variational Variances:  [9.10403450e-06 1.82907624e-04 2.88694882e-05 5.05364764e-05\n",
      " 1.68946133e-04 5.79730647e-05 5.16126611e-04 1.16280711e-04\n",
      " 1.48409457e-04 4.57989598e-04 3.43268382e-04 6.33037872e-04\n",
      " 3.59015669e-04 6.27112033e-04 6.24465149e-04 3.43520852e-04]\n",
      "Iteration 2500 lower bound -1026.2047664698705; gradient mag: 989.0616837560707\n",
      "Variational Mean:  [ 0.80998123 -0.55821834 -1.13064257  0.68723032 -0.56891486 -4.18491333\n",
      " -3.93751609 -5.66402377  4.56245743 -3.97911211  1.95821636 -0.81730482\n",
      " -1.23930949 -1.97584474 -0.87634146 -0.13693501]\n",
      "Variational Variances:  [8.34186696e-06 1.67583438e-04 2.66830073e-05 4.09155601e-05\n",
      " 1.54641112e-04 5.77144097e-05 4.92968357e-04 1.21988185e-04\n",
      " 1.21090695e-04 4.37446926e-04 3.23251060e-04 6.30844702e-04\n",
      " 3.44311119e-04 6.18281730e-04 6.22115984e-04 3.18692834e-04]\n",
      "Iteration 2600 lower bound -1007.5912309896382; gradient mag: 141.8577487778408\n",
      "Variational Mean:  [ 0.80602941 -0.55981331 -1.20835748  0.70604865 -0.57184979 -4.16259034\n",
      " -3.99690137 -6.01076059  4.66277417 -4.039608    1.9787695  -0.82110409\n",
      " -1.24891782 -2.10397133 -0.88190305 -0.15702622]\n",
      "Variational Variances:  [7.67655874e-06 1.54155900e-04 2.48692355e-05 3.33617370e-05\n",
      " 1.41978124e-04 5.73713393e-05 4.76183006e-04 1.28169546e-04\n",
      " 1.00794641e-04 4.20783482e-04 3.05643352e-04 6.33176905e-04\n",
      " 3.33310537e-04 6.08118186e-04 6.22719977e-04 2.96320626e-04]\n",
      "Iteration 2700 lower bound -997.0840863718244; gradient mag: 401.89753799356293\n",
      "Variational Mean:  [ 0.79902888 -0.55609724 -1.26506375  0.72403303 -0.57175063 -4.12452161\n",
      " -4.04708942 -6.27716948  4.74795292 -4.09123414  2.01161864 -0.81335782\n",
      " -1.25571692 -2.207513   -0.87675974 -0.18917635]\n",
      "Variational Variances:  [7.08076254e-06 1.42924539e-04 2.33186201e-05 2.74973583e-05\n",
      " 1.31257357e-04 5.64830270e-05 4.68926860e-04 1.34547411e-04\n",
      " 8.59476050e-05 4.09823391e-04 2.89601852e-04 6.41664535e-04\n",
      " 3.24710108e-04 5.97415621e-04 6.27929245e-04 2.76258254e-04]\n",
      "Iteration 2800 lower bound -989.8741192281423; gradient mag: 331.5296926483761\n",
      "Variational Mean:  [ 0.79121845 -0.54976915 -1.30806733  0.74076133 -0.56955576 -4.08694281\n",
      " -4.08878296 -6.48208089  4.82342596 -4.13534907  2.04467192 -0.80154041\n",
      " -1.2547077  -2.29958745 -0.86680089 -0.22133353]\n",
      "Variational Variances:  [6.54287031e-06 1.33967644e-04 2.19756917e-05 2.29659333e-05\n",
      " 1.22353834e-04 5.52337045e-05 4.72301101e-04 1.40976174e-04\n",
      " 7.50945537e-05 4.07287245e-04 2.75234242e-04 6.58318362e-04\n",
      " 3.17828167e-04 5.85059347e-04 6.39345457e-04 2.58153425e-04]\n",
      "Iteration 2900 lower bound -983.7578179678235; gradient mag: 260.38500818012454\n",
      "Variational Mean:  [ 0.7849825  -0.54051193 -1.3432113   0.75644492 -0.56597421 -4.0558844\n",
      " -4.12363088 -6.64567429  4.89406234 -4.17340444  2.07236483 -0.7893799\n",
      " -1.24795388 -2.38739029 -0.85548266 -0.24819019]\n",
      "Variational Variances:  [6.05536426e-06 1.27046608e-04 2.08038826e-05 1.94367011e-05\n",
      " 1.15102677e-04 5.36106611e-05 4.88956866e-04 1.47936213e-04\n",
      " 6.73473840e-05 4.10780797e-04 2.62319051e-04 6.83747318e-04\n",
      " 3.12008970e-04 5.71328913e-04 6.57377350e-04 2.41681471e-04]\n",
      "Iteration 3000 lower bound -980.7904472553882; gradient mag: 192.76218905852727\n",
      "Variational Mean:  [ 0.78031654 -0.53234886 -1.3716378   0.7713334  -0.56003397 -4.03155481\n",
      " -4.1514654  -6.7807128   4.96081026 -4.20639493  2.09390925 -0.77911053\n",
      " -1.24140408 -2.47348939 -0.8443941  -0.26943606]\n",
      "Variational Variances:  [5.61727376e-06 1.21926968e-04 1.97796280e-05 1.66274960e-05\n",
      " 1.09245957e-04 5.22247906e-05 5.20044879e-04 1.54708704e-04\n",
      " 6.10077226e-05 4.23764306e-04 2.50676930e-04 7.18571796e-04\n",
      " 3.07173566e-04 5.56704705e-04 6.82301026e-04 2.26695307e-04]\n"
     ]
    }
   ],
   "source": [
    "D = 16\n",
    "Sigma_W = np.eye(D)\n",
    "num_samples = 5000\n",
    "max_iterations = 3001\n",
    "step_size = 1e-2\n",
    "\n",
    "# infer variational parameters\n",
    "variational_params = variational_nn_inference(\n",
    "        Sigma_W=Sigma_W,\n",
    "        y_train=ys,\n",
    "        x_train=xs,\n",
    "        S=num_samples,\n",
    "        max_iteration=max_iterations,\n",
    "        step_size=step_size,\n",
    "        verbose=True)\n",
    "var_means = variational_params[:D]\n",
    "var_variance = np.diag(np.exp(variational_params[D:])**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (**Visualize the Posterior Predictive**) Visualize 100 samples $\\mathbf{W}^s$ from your approximate posterior of $\\mathbf{W}$ by ploting the neural network outputs with weight $\\mathbf{W}^s$ plus a random noise $\\epsilon \\sim \\mathcal{N}(0, 0.5^2)$ at 100 equally spaced x-values between -8 and 8:\n",
    "``` python \n",
    "x_test = np.linspace(-8, 8, 100)\n",
    "y_test = nn.forward(sample, x_test.reshape((1, -1)))\n",
    "```\n",
    "  where `sample` is a sample from the approximate posterior of $\\mathbf{W}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the variational posterior\n",
    "posterior_sample_size = 100\n",
    "posterior_samples = numpy.random.multivariate_normal(var_means, var_variance, size=posterior_sample_size)\n",
    "\n",
    "# sample from posterior predictive\n",
    "x_test = numpy.linspace(-8, 8, 100)\n",
    "y_tests, x_tests = [], []\n",
    "for posterior_sample in posterior_samples:\n",
    "    y_test = nn.forward(\n",
    "        posterior_sample.reshape((1, -1)),\n",
    "        x_test.reshape((1, -1))).squeeze()\n",
    "    y_test += numpy.random.normal(loc=0, scale=0.5, size=y_test.shape)\n",
    "    x_tests.append(x_test)\n",
    "    y_tests.append(y_test)\n",
    "x_tests = numpy.concatenate(x_tests)\n",
    "y_tests = numpy.concatenate(y_tests)\n",
    "\n",
    "# append MLE\n",
    "y_mle = nn.forward(nn.weights, x_test.reshape((1, -1))).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot posterior predictive\n",
    "\n",
    "from IPython.display import Image\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "plot_data = [\n",
    "    go.Scatter(x=x_tests, y=y_tests, mode='markers', name='Posterior Predictive'),\n",
    "    go.Scatter(x=x_test, y=y_mle, name='MLE'),\n",
    "    go.Scatter(x=xs, y=ys, mode='markers', name='Original Data')]\n",
    "fig = go.Figure(data=plot_data)\n",
    "# fig.show()\n",
    "Image(pio.to_image(fig, format='png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (**Computing the Fit**) Compute the posterior predictive log likelihood of the observed data under your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior Predictive Log Likelihood:  -4.937597984226093\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "log_likelihoods = np.zeros(posterior_samples.shape[0])\n",
    "for i, posterior_sample in enumerate(posterior_samples):\n",
    "    y_mean = nn.forward(\n",
    "        posterior_sample.reshape((1, -1)),\n",
    "        xs.reshape((1, -1))).squeeze()\n",
    "    log_like = norm.logpdf(ys, loc=y_mean, scale=0.5)\n",
    "    log_likelihoods[i] = log_like.sum()\n",
    "print('Posterior Predictive Log Likelihood: ', numpy.mean(log_likelihoods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (**Model Evaluation**) Compare the posterior predictive visualization and the posterior predictive log likelihood obtained from BBVI with the reparametrization trick to the ones you obtained in HW #7. Can you say whether or not your posterior approximation is good? How does approximating the posterior effect our estimation of epistemic and aleatoric uncertainty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared against Homework 7's Hamiltonian Monte Carlo posterior samples, it appears that BBVI is a better model based on its more positive posterior predictive log likelihood (approximately -4.9 versus HMC's -8.72). In fairness, I'm not sure that this is a meaningful conclusion since the competition doesn't have comparable parameters. What I mean by this is that for HMC, I generated 10000 total samples, and took 50 steps per leapfrog step, whereas for BBVI, I generated 4000 samples and optimized for 3000 iterations, and I don't know how to compare these parameters against each other. Was equivalent computational work performed? I don't know.\n",
    "\n",
    "Empirically, I can say that it appears neither model converged. HMC's trace plots were still trending, while BBVI's lower bound was still increasing and its gradients still large.\n",
    "\n",
    "Subjectively, I think that HMC provided a better posterior approximation. I say this because although both HMC and BBVI have low aleatoric uncertainty near known points (x=-5, x=5), HMC generated a very wide posterior predictive distribution in the range $x \\in [-3, 3]$, which accords with our intuition that we should have high epistemic uncertainty because we have no data in this range. In contrast, BBVI has much lower uncertainty in the range $x \\in [-3, 3]$, which makes me concerned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
