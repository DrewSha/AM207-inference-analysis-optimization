{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture #7: Latent Variable Models and MLE\n",
    "## AM 207: Advanced Scientific Computing\n",
    "### Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "### Fall, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"fig/logos.jpg\" style=\"height:150px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### Import basic libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Administrative Matters\n",
    "\n",
    "1. **Attendance Quiz:** <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "0. Review of Statistical Modeling\n",
    "1. Motivation for Latent Variable Models\n",
    "2. Common Latent Variable Models\n",
    "3. Maximum Likelihood Estimation for Latent Variable Models: Expectation Maximization\n",
    "4. Mixture of Gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review of Statistical Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What We Can Do So Far\n",
    "1. **(Models)** When we have observed data $Y_{\\text{Obs}}$, we can model $Y_{\\text{Obs}}$ as a random variable $Y_{\\text{Obs}} \\sim p(Y |\\theta)$ with a known distribution $p$.\n",
    "  - if $Y_{\\text{Obs}}$ is a label, we can model it as a *Categorical* or *Bernoulli* variable\n",
    "  - if $Y_{\\text{Obs}}$ is a count, we can model it as a *Binomial*, *Multinomial* or *Poisson*\n",
    "  - if $Y_{\\text{Obs}}$ is continuous, we can model it as a *Gaussian*, *Exponential*, *Dirichlet* etc\n",
    " \n",
    "2. **(Inference)** We can make statements about $\\theta$ by performing:\n",
    "   - ***Maximum Likelihood Estimation:*** compute a fixed value $\\theta_{\\text{MLE}}$ that maximizes the likelihood of the observed data $Y$.\n",
    "   - ***Bayesian Inference:*** *assume* a prior for $\\theta$, encoding our knowledge and uncertainty about $\\theta$, then compute the posterior $p(\\theta| Y)$ distribution. \n",
    "   \n",
    "3. **(Inference Algorithm)** We choose an algorithm to perform inference:\n",
    "\n",
    "  - ***Maximum Likelihood Estimation:*** *analytically* solve an unconstrained or contrained optimization problem to obtain $\\theta_{\\text{MLE}}$.\n",
    "  - ***Bayesian Inference:*** \n",
    "    - if the prior and likelihood are ***conjugate***, then *analytically* derive the posterior distribution\n",
    "    - if the posterior distribution does not have a known (to you) form, sample from it using a ***sampler***.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Happens After Inference?\n",
    "\n",
    "1. **(Predictive Evaluation)** In practice, we do not know the true model $\\theta_{\\text{True}}$! Thus, $\\theta_{\\text{MLE}}$ and $p(\\theta|Y)$ cannot be evaluated by comparison to $\\theta_{\\text{True}}$.\n",
    "  - ***Maximimum Likelihood Estimation:*** we sample multiple $Y \\sim p(Y| \\theta_{\\text{MLE}})$ and compare with observed data $Y_{\\text{Obs}}$.\n",
    "  - ***Bayesian Inference:*** we sample multiple $Y$ from the ***posterior predictive*** and compare with observed data $Y_{\\text{Obs}}$.<br><br>\n",
    "\n",
    "2. **(Uncertainty Evaluation)** Before making decisions with real-life consequence based on your model, you should check the precision of your estimate or uncertainty of you model.\n",
    "  - ***Maximimum Likelihood Estimation:*** repeat the MLE computation on many bootstrap samples of $Y_{\\text{Obs}}$. Compute the confidence interval of $\\theta$ and the predictive interval for $Y$. These intervals indicate *precision*.\n",
    "  - ***Bayesian Inference:*** Compute credible intervals for the posterior $p(\\theta|Y)$ and the predictive intervals of the posterior predictive. These intervals indicate *model uncertainty*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Modeling Process\n",
    "\n",
    "<img src=\"fig/modeling.jpg\" style=\"height:250px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation for Latent Variable Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Model for Birth Weights\n",
    "Recall our model for birth weigths, $Y_1,\\ldots, Y_N$. We *posited* that the birth weights are iid normally distributed with known $\\sigma^2$, $Y_n \\sim \\mathcal{N}(\\mu, 1)$.\n",
    "\n",
    "Compare the maximum likelihood model and the Bayesian model for bith weight. Which model would you use to make clinical decisions? What's hard about this comparison?\n",
    "\n",
    "<img src=\"fig/compare.jpg\" style=\"height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Similarity Measure for Distributions: Kullback–Leibler Divergence\n",
    "\n",
    "Visually comparing models to the ***empirical distribution*** of the data is impractical. Fortunately, there are a large number of quantitative measures for comparing two distributions, these are called ***divergence measures***. For example, the ***Kullback–Leibler (KL) Divergence*** is defined for two distributions $p(\\theta)$ and $q(\\theta)$ supported on $\\Theta$ as:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}[q \\,\\|\\, p] = \\int_{\\Theta} \\log\\left[\\frac{q(\\theta)}{p(\\theta)} \\right] q(\\theta)d\\theta\n",
    "$$\n",
    "\n",
    "The KL-divergence $D_{\\text{KL}}[q \\,\\|\\, p]$ is bounded below by 0, which happens if and only if $q=p$.\n",
    "The KL-divergence has information theoretic interpretations that we will explore later in the course.\n",
    "\n",
    "**Note:** The KL-divergence is defined in terms of the pdf's of $p$ and $q$. If $p$ is a distribution from which we only have samples and not the pdf (like the empirical distribution), we can nontheless estimate $D_{\\text{KL}}[q \\,\\|\\, p]$. Techniques that estimate the KL-divergence from samples are called ***non-parametric***. We will use them later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Class Membership as a Latent Variable\n",
    "\n",
    "We observe that there are three ***clusters*** in the data. We posit that there are three ***classes*** of infants in the study: infants with low birth weights, infants with normal birth weights and those with high birth weights. The numbers of infants in the classes are not equal.\n",
    "\n",
    "For each observation $Y_n$, we model its class membership $Z_n$ as a categorical variable, \n",
    "\n",
    "$$Z_n\\sim Cat(\\pi),$$\n",
    "\n",
    "where $\\pi_i$ in $\\pi = [\\pi_1, \\pi_2, \\pi_3]$ is the class proportion. Note that we don't have the class membership $Z_n$ in the data! So $Z_n$ is called a ***latent variable***.\n",
    "\n",
    "Depending on the class, the $n$-th birth weight $Y_n$ will have a different normal distribution,\n",
    "\n",
    "$$\n",
    "Y_n | Z_n \\sim \\mathcal{N}\\left(\\mu_{Z_n}, \\sigma^2_{Z_n}\\right)\n",
    "$$\n",
    "\n",
    "where $\\mu_{Z_n}$ is one of the three class means $[\\mu_1, \\mu_2, \\mu_3]$ and $\\sigma^2_{Z_n}$ is one of the three class variances $[\\sigma^2_1, \\sigma^2_2, \\sigma^2_3]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Common Latent Variable Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Latent Variable Models\n",
    "\n",
    "Models that include an observed variable $Y$ and at least one unobserved variable $Z$ are called ***latent variable models***. In general, our model can allow $Y$ and $Z$ to interact in many different ways. Today, we will study models with one type of interaction:\n",
    "\n",
    "<img src=\"fig/graphical_model.jpg\" style=\"height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Gaussian Mixture Models (GMMs)\n",
    "\n",
    "In a ***Gaussian Mixture Model (GMM)***, we posit that the observed data $Y$ is generated by a mixture, $\\pi=[\\pi_1, \\ldots, \\pi_K]$, of $K$ number of Gaussians with means $\\mu = [\\mu_1, \\ldots, \\mu_K]$ and covariances $\\Sigma = [\\Sigma_1, \\ldots, \\Sigma_K]$. For each observation $Y_n$ the class of the observation $Z_n$ is a latent variable that indicates which of the $K$ Gaussian is responsible for generating $Y_n$:\n",
    "\n",
    "\\begin{aligned}\n",
    "Z_n &\\sim Cat(\\pi),\\\\\n",
    "Y_n | Z_n&\\sim \\mathcal{N}(\\mu_{Z_n}, \\Sigma_{Z_n}),\n",
    "\\end{aligned}\n",
    "where $n=1, \\ldots, N$ and $\\sum_{k=1}^K \\pi_k = 1$. \n",
    "\n",
    "GMMs are examples of ***model based clustering*** - breaking up a data set into natural clusters based on a statistical model fitted to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Item-Response Models\n",
    "\n",
    "In ***item-response models***, we measure an real-valued unobserved trait $Z$ of a subject by performing a series of experiments with binary observable outcomes, $Y$:\n",
    "\n",
    "\\begin{aligned}\n",
    "Z_n &\\sim \\mathcal{N}(\\mu, \\sigma^2),\\\\\n",
    "\\theta_n &= g(Z_n)\\\\\n",
    "Y_n|Z_n &\\sim Ber(\\theta_n),\n",
    "\\end{aligned}\n",
    "\n",
    "where $n=1, \\ldots, N$ and $g$ is some fixed function of $Z_n$.\n",
    "\n",
    "#### Applications\n",
    "Item response models are used to model the way \"underlying intelligence\" $Z$ relates to scores $Y$ on IQ tests. \n",
    "\n",
    "Item response models can also be used to model the way \"suicidality\" $Z$ relates to answers on mental health surveys. Building a good model may help to infer when a patient is at psychiatric risk based on in-take surveys at points of care through out the health-care system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Factor Analysis Models\n",
    "\n",
    "In ***factor analysis models***, we posit that the observed data $Y$ with many measurements is generated by a small set of unobserved factors $Z$:\n",
    "\n",
    "\\begin{aligned}\n",
    "Z_n &\\sim \\mathcal{N}(0, I),\\\\\n",
    "Y_n|Z_n &\\sim \\mathcal{N}(\\mu + \\Lambda Z_n, \\Phi),\n",
    "\\end{aligned}\n",
    "\n",
    "where $n=1, \\ldots, N$, $Z_n\\in \\mathbb{R}^{D'}$ and $Y_n\\in \\mathbb{R}^{D}$. We typically assume that $D'$ is much smaller than $D$.\n",
    "\n",
    "#### Applications\n",
    "Factor analysis models are useful for biomedical data, where we typically measure a large number of characteristics of a patient (e.g. blood pressure, heart rate, etc), but these characteristics are all generated by a small list of health factors (e.g. diabetes, cancer, hypertension etc). Building a good model means we may be able to infer the list of health factors of a patient from their observed measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Maximum Likelihood Estimation for Latent Variable Models: Expectation Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Expectation Maximization: Estimating the MLE for Latent Variable Models\n",
    "\n",
    "Given a latent variable model $p(Y, Z| \\phi, \\theta) = p(Y | Z, \\phi) p(Z|\\theta)$, we are interested computing the MLE of parameters $\\phi$ and $\\theta$:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\theta_{\\text{MLE}}, \\phi_{\\text{MLE}} &= \\underset{\\theta, \\phi}{\\mathrm{argmax}}\\; \\ell(\\theta, \\phi)\\\\\n",
    "&= \\underset{\\theta, \\phi}{\\mathrm{argmax}}\\; \\log \\prod_{n=1}^N \\int_{\\Omega_Z}  p(y_n, z_n | \\theta, \\phi) dz\\\\\n",
    "&= \\underset{\\theta, \\phi}{\\mathrm{argmax}}\\; \\log \\prod_{n=1}^N \\int_{\\Omega_Z}  p(y_n| z_n, \\phi)p(z_n| \\theta) dz\n",
    "\\end{aligned}\n",
    "where $\\Omega_Z$ is the domain of $Z$.\n",
    "Why is this an hard optimization problem?\n",
    "\n",
    "There are two major problems: \n",
    "1. the product in the integrand\n",
    "2. gradients cannot be past the integral (i.e. we cannot easily compute the gradient to solve the optimization problem). \n",
    "\n",
    "We solve these two problems by: \n",
    "1. pushing the log past the integral so that it can be applied to the integrand (Jensen's Inequality)\n",
    "2. introducing an auxiliary variables $q(Z_n)$ to allow the gradient to be pushed past the integral.\n",
    "\n",
    "\\begin{aligned}\n",
    "\\underset{\\theta, \\phi}{\\mathrm{max}}\\; \\ell(\\theta, \\phi) &= \\underset{\\theta, \\phi, q}{\\mathrm{max}}\\; \\log \\prod_{n=1}^N\\int_{\\Omega_Z} \\left(\\frac{p(y_n, z_n|\\theta, \\phi)}{q(z_n)}q(z_n)\\right) dz\\\\\n",
    "&= \\underset{\\theta, \\phi, q}{\\mathrm{max}}\\; \\log\\,\\prod_{n=1}^N\\mathbb{E}_{Z\\sim q(Z)} \\left[  \\frac{p(y_n, Z|\\theta, \\phi)}{q(Z)}\\right]\\\\\n",
    "&= \\underset{\\theta, \\phi, q}{\\mathrm{max}}\\; \\sum_{n=1}^N \\log \\mathbb{E}_{Z\\sim q(Z)} \\left[\\,\\left( \\frac{p(y_n, Z|\\theta, \\phi)}{q(Z)}\\right)\\right]\\\\\n",
    "&\\geq \\underset{\\theta, \\phi, q}{\\mathrm{max}}\\; \\underbrace{\\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim q(Z)} \\left[  \\log\\,\\left(\\frac{p(y_n, Z_n|\\theta, \\phi)}{q(Z_n)}\\right)\\right]}_{ELBO(\\theta, \\phi)}, \\quad (\\text{Jensen's Inequality})\\\\\n",
    "\\end{aligned}\n",
    "\n",
    "We call $\\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim q(Z)} \\left[ \\log\\,\\left(\\frac{p(y_n, Z_n|\\theta, \\phi)}{q(Z)}\\right)\\right]$ the Evidence Lower Bound (ELBO). Note that maximizing the ELBO will yield a lower bound of the maximum value of the log likelihood. Although **the optimal point of the ELBO may not be the optimal point of the log likelihood**, we nontheless prefer to optimize the ELBO because the gradients, with respect to $\\theta, \\phi$, of the ELBO are easier to compute:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta, \\phi} ELBO(\\theta, \\phi) = \\nabla_{\\theta, \\phi}\\left[ \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim q(Z)} \\left[  \\log\\,\\left(\\frac{p(y_n, Z_n|\\theta, \\phi)}{q(Z_n)}\\right)\\right]\\right] =  \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim q(Z)} \\left[  \\nabla_{\\theta, \\phi} \\left( \\log\\,\\left(\\frac{p(y_n, Z_n|\\theta, \\phi)}{q(Z_n)}\\right)\\right)\\right]\n",
    "$$\n",
    "\n",
    "Note that we can push the gradient $\\nabla_{\\theta, \\phi}$ past the expectation $\\mathbb{E}_{Z_n\\sim q(Z)}$ since the expectation is not computed with respect to our optimization variables!\n",
    "\n",
    "Rather than optimizing the ELBO over all variables $\\theta, \\phi, q$ (this would be hard), we optimize one set of variables at a time:\n",
    "\n",
    "#### Step I: the M-step\n",
    "Optimize the ELBO with respect to $\\theta, \\phi$:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\theta^*, \\phi^* = \\underset{\\theta, \\phi}{\\mathrm{max}}\\; ELBO(\\theta, \\phi, q) &= \\underset{\\theta, \\phi}{\\mathrm{max}}\\; \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim q(Z)} \\left[  \\log\\,\\left(\\frac{p(y_n, Z_n|\\theta, \\phi)}{q(Z_n)}\\right)\\right]\\\\\n",
    "&= \\underset{\\theta, \\phi}{\\mathrm{max}}\\;  \\sum_{n=1}^N \\int_{\\Omega_Z} \\log\\,\\left(\\frac{p(y_n, z_n|\\theta, \\phi)}{q(z_n)}\\right)q(z_n) dz_n\\\\\n",
    "&= \\underset{\\theta, \\phi}{\\mathrm{max}}\\; \\sum_{n=1}^N \\int_{\\Omega_Z} \\log\\,\\left(p(y_n, z_n|\\theta, \\phi)\\right) q(z_n)dz_n - \\underbrace{\\int_{\\Omega_Z} \\log \\left(q(z_n)\\right)q(z_n) dz_n}_{\\text{constant with respect to }\\theta, \\phi}\\\\\n",
    "&\\equiv \\underset{\\theta, \\phi}{\\mathrm{max}}\\;\\sum_{n=1}^N \\int_{\\Omega_Z} \\log\\,\\left(p(y_n, z_n|\\theta, \\phi)\\right) q(z_n)dz_n\\\\\n",
    "&= \\underset{\\theta, \\phi}{\\mathrm{max}}\\;\\sum_{n=1}^N \\mathbb{E}_{Z_n\\sim q(Z)} \\left[ \\log\\left(p(y_n, z_n|\\theta, \\phi)\\right)\\right]\n",
    "\\end{aligned}\n",
    "\n",
    "#### Step II: the E-step\n",
    "Optimize the ELBO with respect to $q$:\n",
    "\n",
    "\\begin{aligned}\n",
    "q^*(Z_n) = \\underset{q}{\\mathrm{argmax}}\\;\\left(\\underset{\\theta, \\phi}{\\mathrm{argmax}}\\; ELBO(\\theta, \\phi, q) \\right) = \\underset{q}{\\mathrm{argmax}}\\; ELBO(\\theta^*, \\phi^*, q)\n",
    "\\end{aligned}\n",
    "\n",
    "Rather than optimizing the ELBO with respect to $q$, which seems hard, we will argue that optimizing the ELBO is equivalent to optimizing another function of $q$, one whose optimum is easy for us to compute.\n",
    "\n",
    "**Note:** We can recognize the difference between the log likelihood and the ELBO as a function we've seen:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\ell(\\theta, \\phi) - ELBO(\\theta, \\phi, q) &= \\sum_{n=1}^N \\log p(y_n| \\theta, \\phi) - \\sum_{n=1}^N \\int_{\\Omega_Z} \\log\\left(\\frac{p(y_n, z_n|\\theta, \\phi)}{q(z_n)}\\right)q(z_n) dz_n\\\\\n",
    "&=  \\sum_{n=1}^N \\int_{\\Omega_Z} \\log\\left(p(y_n| \\theta, \\phi)\\right) q(z_n) dz_n - \\sum_{n=1}^N \\int_{\\Omega_Z} \\log\\left(\\frac{p(y_n, z_n|\\theta, \\phi)}{q(z_n)}\\right)q(z_n) dz_n\\\\\n",
    "&=  \\sum_{n=1}^N \\int_{\\Omega_Z}  \\left(\\log\\left(p(y_n| \\theta, \\phi)\\right) - \\log\\left(\\frac{p(y_n, z_n|\\theta, \\phi)}{q(z_n)}\\right) \\right)q(z_n) dz_n\\\\\n",
    "&= \\sum_{n=1}^N \\int_{\\Omega_Z}  \\log\\left(\\frac{p(y_n| \\theta, \\phi)q(z_n)}{p(y_n, z_n|\\theta, \\phi)} \\right)q(z_n) dz_n\\\\\n",
    "&= \\sum_{n=1}^N \\int_{\\Omega_Z}  \\log\\left(\\frac{q(z_n)}{p(z_n| y_n, \\theta, \\phi)} \\right)q(z_n) dz_n, \\quad\\left(\\text{Baye's Rule: } \\frac{p(y_n, z_n|\\theta, \\phi)}{p(y_n| \\theta, \\phi)} = p(z_n| y_n, \\theta, \\phi)\\right)\\\\\n",
    "&= \\sum_{n=1}^N D_{\\text{KL}} \\left[ q(Z_n) \\| p(Z_n| Y_n, \\theta, \\phi)\\right].\n",
    "\\end{aligned}\n",
    "\n",
    "Since $\\ell(\\theta, \\phi)$ is a constant, the difference $\\sum_{n=1}^N D_{\\text{KL}} \\left[ q(Z_n) \\| p(Z_n| Y_n, \\theta, \\phi)\\right] = \\ell(\\theta, \\phi) - ELBO(\\theta, \\phi, q)$ descreases when $ELBO(\\theta, \\phi, q)$ increases (and vice versa). Thus, maximizing the ELBO is equivalent to minimizing $D_{\\text{KL}} \\left[ q(Z_n) \\| p(Y_n| Z_n, \\theta, \\phi)\\right]$:\n",
    "\n",
    "$$\n",
    "\\underset{q}{\\mathrm{argmax}}\\, ELBO(\\theta, \\phi, q) = \\underset{q}{\\mathrm{argmin}}\\sum_{n=1}^N D_{\\text{KL}} \\left[ q(Z_n) \\| p(Z_n| Y_n, \\theta, \\phi)\\right].\n",
    "$$\n",
    "\n",
    "Thus, we see that \n",
    "\\begin{aligned}\n",
    "q^*(Z_n) = \\underset{q}{\\mathrm{argmax}}\\; ELBO(\\theta^*, \\phi^*, q) = \\underset{q}{\\mathrm{argmin}}\\sum_{n=1}^N D_{\\text{KL}} \\left[ q(Z_n) \\| p(Z_n| Y_n, \\theta, \\phi)\\right] = p(Z_n| Y_n, \\theta, \\phi)\n",
    "\\end{aligned}\n",
    "\n",
    "That is, we should set the optimal distribution $q$ to be the posterior $p(Z_n| Y_n, \\theta, \\phi)$.\n",
    "\n",
    "#### Iteration\n",
    "Of course, we know that optimizing a function with respect to each variable is not sufficient for finding the global optimum over all the variables, considered together! Thus, performing one E-step and one M-step is not enough to maximize the ELBO. We need to repeat the two steps over and over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Expectation Maximization Algorithm\n",
    "\n",
    "The ***exepectation maximization (EM) algorithm*** maximize the ELBO of the model,\n",
    "<img src=\"fig/graphical_model.jpg\" style=\"height:150px;\">\n",
    "0. **Initialization:** Pick $\\theta_0$, $\\phi_0$.\n",
    "1. Repeat $i=1, \\ldots, I$ times:\n",
    "\n",
    "  **E-Step:** \n",
    "$$q_{\\text{new}}(Z_n) = \\underset{q}{\\mathrm{argmax}}\\; ELBO(\\theta_{\\text{old}}, \\phi_{\\text{old}}, q) = p(Z_n|Y_n, \\theta_{\\text{old}}, \\phi_{\\text{old}})$$\n",
    "\n",
    "  **M-Step:** \n",
    "  \\begin{aligned}\n",
    "  \\theta_{\\text{new}}, \\phi_{\\text{new}} &= \\underset{\\theta, \\phi}{\\mathrm{argmax}}\\; ELBO(\\theta, \\phi, q_{\\text{new}})\\\\\n",
    "  &= \\underset{\\theta, \\phi}{\\mathrm{argmax}}\\; \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim p(Z_n|Y_n, \\theta_{\\text{old}}, \\phi_{\\text{old}})}\\left[\\log \\left( p(y_n, Z_n | \\phi, \\theta\\right) \\right].\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## The Auxiliary Function\n",
    "\n",
    "We often denote the expectation in the M-step by $Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)$\n",
    "$$\n",
    "Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right) = \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim p(Z_n|Y_n, \\theta_{\\text{old}}, \\phi_{\\text{old}})}\\left[\\log \\left( p(y_n, Z_n | \\phi, \\theta\\right) \\right]\n",
    "$$\n",
    "and call $Q$ the auxiliary function. \n",
    "\n",
    "Frequently, the EM algorithm is equivalently presented as\n",
    "- E-step: compute the auxiliary function: $Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)$\n",
    "- M-step: maximize the auxiliary function: $\\theta^{\\text{new}}, \\phi^{\\text{new}} = \\underset{\\theta, \\phi}{\\mathrm{argmax}}\\,Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)$.\n",
    "\n",
    "The log of the joint distribution $\\prod_{n=1}^N p(Z_n, Y_n, \\theta, \\phi)$ is called the ***complete data log-likelihood*** (since it is the likelihood of both observed and latent variables), whereas $\\log \\prod_{n=1}^N p(Y_n| \\theta, \\phi)$ is called the ***observed data log-likelihood*** (since it is the likelihood of only the observed variable).\n",
    "\n",
    "The auxiliary function presentation of EM is easy to interpret:\n",
    "- In the E-step, you fill in the latent variables in the complete data log-likelihood using \"average\" values, this leaves just an estimate of the observed log-likelihood.\n",
    "- In the M-step, you find parameters $\\phi$ and $\\theta$ that maximizes your estimate of the observed log-likelihood.\n",
    "\n",
    "We chose to derive EM via the ELBO in this lecture because it makes an explicit connection between the EM algorithm for estimating MLE and variational inference method for approximating the posterior of Bayesian models. It is, however, worthwhile to derive EM using the auxiliary function $Q$, as $Q$ makes it convient for us to prove properties of the EM algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Monotonicity and Convergence of EM\n",
    "\n",
    "Before we run off estimating MLE parameters of latent variable models with EM, we need to sanity check two points:\n",
    "\n",
    "1. **(Monotonicity)** we need to know that repeating the E, M-steps will never decrease the ELBO!\n",
    "2. **(Convergence)** we need to know that at some point the EM algorithm will naturally terminate (the algorithm will cease to update the parameters).\n",
    "\n",
    "We first prove the monotonicity of EM. Consider the difference between $\\ell(\\theta, \\phi) - \\ell(\\theta^{\\text{old}}, \\phi^{\\text{old}})$, i.e. the amount by which the log-likelihood can increase or decrease by going from $\\theta^{\\text{old}}, \\phi^{\\text{old}}$ to $\\theta, \\phi$:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\ell(\\theta, \\phi) - \\ell(\\theta^{\\text{old}}, \\phi^{\\text{old}}) &= \\sum_{n=1}^N\\log \\left[ \\frac{p(y_n|\\theta, \\phi)}{p(y_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})}\\right]\\\\\n",
    "&= \\sum_{n=1}^N \\log\\int \\frac{p(y_n, z_n|\\theta, \\phi)}{p(y_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})} dz_n\\\\\n",
    "&= \\sum_{n=1}^N \\log\\int \\frac{p(y_n, z_n|\\theta, \\phi)}{p(y_n| \\theta^{\\text{old}}, \\phi^{\\text{old}}) p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}})}p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}}) dz_n\\\\\n",
    "&= \\sum_{n=1}^N \\log\\int \\frac{p(y_n, z_n|\\theta, \\phi)}{p(y_n, z_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})}p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}}) dz_n\\\\\n",
    "&= \\sum_{n=1}^N \\log \\mathbb{E}_{p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}})} \\left[\\frac{p(y_n, z_n|\\theta, \\phi)}{p(y_n, z_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})}\\right]\\\\\n",
    "&\\geq \\sum_{n=1}^N  \\mathbb{E}_{p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}})} \\log\\left[\\frac{p(y_n, z_n|\\theta, \\phi)}{p(y_n, z_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})}\\right]\\\\\n",
    "&= \\sum_{n=1}^N  \\mathbb{E}_{p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}})} \\left[\\log  p(y_n, z_n|\\theta, \\phi) - \\log p(y_n, z_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})\\right]\\\\\n",
    "&= \\sum_{n=1}^N  \\mathbb{E}_{p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}})} \\left[\\log  p(y_n, z_n|\\theta, \\phi)\\right] - \\sum_{n=1}^N  \\mathbb{E}_{p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}})}\\left[ \\log  p(y_n, z_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})\\right]\\\\\n",
    "&= Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right) - Q\\left(\\theta^{\\text{old}}, \\phi^{\\text{old}}| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "Thus, when we maximize the gain in log-likelihood going from $\\theta^{\\text{old}}, \\phi^{\\text{old}}$ to $\\theta, \\phi$, we get:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\underset{\\theta, \\phi}{\\max} \\left[\\ell(\\theta, \\phi) - \\ell(\\theta^{\\text{old}}, \\phi^{\\text{old}})\\right] \\geq \\underset{\\theta, \\phi}{\\max} \\left[Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right) - Q\\left(\\theta^{\\text{old}}, \\phi^{\\text{old}}| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)\\right]\n",
    "\\end{aligned}\n",
    "\n",
    "or equivalently,\n",
    "\n",
    "\\begin{aligned}\n",
    "\\underset{\\theta, \\phi}{\\max} \\left[\\ell(\\theta, \\phi)\\right] - \\ell(\\theta^{\\text{old}}, \\phi^{\\text{old}}) \\geq \\underset{\\theta, \\phi}{\\max} \\left[Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)\\right] - Q\\left(\\theta^{\\text{old}}, \\phi^{\\text{old}}| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right).\n",
    "\\end{aligned}\n",
    "\n",
    "Note that the above max is always greater than or equal to zero: \n",
    "\n",
    "$$\\underset{\\theta, \\phi}{\\max} \\left[Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)\\right] - Q\\left(\\theta^{\\text{old}}, \\phi^{\\text{old}}| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right) \\geq 0$$ \n",
    "\n",
    "since we can always maintain the status quo by choosing $theta = \\theta^{\\text{old}}$ $\\phi = \\phi^{\\text{old}}$:\n",
    "\n",
    "$$ Q\\left(\\theta^{\\text{old}}, \\phi^{\\text{old}}| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right) - Q\\left(\\theta^{\\text{old}}, \\phi^{\\text{old}}| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right) = 0.$$\n",
    "\n",
    "Thus, we have that by maximizing $Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)$, we ensure that $\\ell(\\theta, \\phi) - \\ell(\\theta^{\\text{old}}, \\phi^{\\text{old}})\\geq 0$ in each iteration of EM.\n",
    "\n",
    "\n",
    "If the likelihood of the model is bounded above (i.e. $\\ell(\\theta, \\phi) \\leq M$ for some constant $M$), then EM is guaranteed to convergence. This is because we've proved that EM increases (or maintains) log-likelihood in each iteration, therefore, if $\\ell(\\theta, \\phi)$ is bounded, the process must converge. \n",
    "\n",
    "\n",
    "#### Disclaimer:\n",
    "Although EM converges for bounded likelihoods, it is not guaranteed to converge to the global max of the log-likelihood! Maximizing a lower bound of a function does not necessarily maximize the function itself! Often time, EM converges to local optima of the likelihood function and the point to which it converges may be very sensitive to initialization. We will study this kind of behaviour in more detail when we cover non-convex optimization later in the course.\n",
    "\n",
    "<img src=\"fig/EM.jpg\" style=\"height:350px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Example: EM for the Gaussian Mixture Model of Birth Weight\n",
    "The Gaussian mixture model for the birth weight data has 3 Gaussians with meand $\\mu = [\\mu_1, \\mu_2, \\mu_3]$ and variances $\\sigma^2 = [\\sigma_1^2, \\sigma_2^2, \\sigma_3^2]$, and the model is defined as:\n",
    "\\begin{aligned}\n",
    "Z_n &\\sim Cat(\\pi),\\\\\n",
    "Y_n &\\sim \\mathcal{N}(\\mu_{Z_n}, \\sigma^2_{Z_n}),\n",
    "\\end{aligned}\n",
    "where $n=1, \\ldots, N$ and $\\sum_{k=1}^3 \\pi_k = 1$. \n",
    "\n",
    "### The E-Step\n",
    "\n",
    "The E-step in EM computes the distribution:\n",
    "$$q_{\\text{new}}(Z_n) = \\underset{q}{\\mathrm{argmax}}\\; ELBO(\\mu_{i-1}, \\sigma^2_{i-1}, \\pi_{i_1}, q) = p(Z_n|Y_n, \\mu_{\\text{old}}, \\sigma^2_{\\text{old}}, \\pi_{\\text{old}}).$$ \n",
    "Since $Z_n$ is a label, $p(Z_n|Y_n, \\ldots)$ is a categorical distribution, with the probability of $Z_n=k$ given by:\n",
    "\n",
    "$$\n",
    "p(Z_n = k|Y_n, \\mu_{\\text{old}}, \\sigma^2_{\\text{old}}, \\pi_{\\text{old}}) = \\frac{p(y_n|Z_n = k, \\mu_{\\text{old}}, \\sigma^2_{\\text{old}})p(Z_n=k | \\pi_{\\text{old}})}{\\sum_{k=1}^K p(y|Z_n = k, \\mu_{\\text{old}}, \\sigma^2_{\\text{old}})p(Z_n=k | \\pi_{\\text{old}})} = \\underbrace{\\frac{\\pi_{k, \\text{old}}\\,\\mathcal{N}(y_n; \\mu_{k, \\text{old}}, \\sigma^2_{k, \\text{old}})}{\\mathcal{Z}}}_{r_{n, k}},\n",
    "$$\n",
    "where $\\mathcal{Z} = \\sum_{k=1}^K \\pi_{k, \\text{old}}\\,\\mathcal{N}(y_n; \\mu_{k, \\text{old}}, \\sigma^2_{k, \\text{old}})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Example: EM for the Gaussian Mixture Model of Birth Weight\n",
    "### Setting Up the M-Step\n",
    "\n",
    "The M-step in EM maximize the following: \n",
    "$$\\underset{\\mu, \\sigma^2, \\pi}{\\mathrm{argmax}}\\; ELBO(\\mu, \\sigma^2, \\pi, q_{\\text{new}}) = \\underset{\\mu, \\sigma^2, \\pi}{\\mathrm{argmax}}\\; \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim p(Z_n|Y_n, \\mu_{k, \\text{old}}, \\sigma^2_{k, \\text{old}})}\\left[\\log \\left( p(y_n, Z_n | \\mu, \\sigma^2, \\pi\\right) \\right].$$\n",
    "\n",
    "If we expand the expectation a little, we get:\n",
    "\\begin{aligned}\n",
    "\\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim p(Z_n|Y_n, \\mu_{\\text{old}}, \\sigma^2_{\\text{old}}, \\pi_{\\text{old}})}\\left[\\log \\left(p(y_n, Z_n | \\mu, \\sigma^2, \\pi) \\right) \\right] &= \\sum_{n=1}^N \\underbrace{\\sum_{n=1}^K \\log \\left(\\underbrace{ p(y_n| Z_n=k, \\mu, \\sigma^2) p(Z_n=k| \\pi)}_{\\text{factoring the joint }p(y_n, Z_n| \\ldots) } \\right) p(Z_n=k|y_n, \\theta_{\\text{old}}, \\phi_{\\text{old}})}_{\\text{expanding the expectation}}\\\\\n",
    "&=\\sum_{n=1}^N \\sum_{k=1}^K \\underbrace{r_{n, k}}_{p(Z_n=k|y_n, \\theta_{\\text{old}}, \\phi_{\\text{old}})} \\left[\\log \\underbrace{\\mathcal{N}(y_n; \\mu_k, \\sigma^2_k)}_{p(y_n| Z_n=k, \\mu, \\sigma^2)}  + \\log \\underbrace{\\pi_k}_{p(Z_n=k| \\pi)}\\right]\\\\\n",
    "&= \\underbrace{\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log \\mathcal{N}(y_n; \\mu_k, \\sigma^2_k)}_{\\text{Term #1}} + \\underbrace{\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k}\\pi_k}_{\\text{Term #2}} \n",
    "\\end{aligned}\n",
    "We can maximize each Term #1 and Term #2 individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: EM for the Gaussian Mixture Model of Birth Weight\n",
    "### Solving the M-Step\n",
    "\n",
    "We see that the optimization problem in the M-step: $\\mu_{\\text{new}}, \\sigma^2_{\\text{new}}, \\pi_{\\text{new}} = \\underset{\\mu, \\sigma^2, \\pi}{\\mathrm{argmax}}\\; ELBO(\\mu, \\sigma^2, \\pi, q_{\\text{new}})$ is equivalent to two problems\n",
    "\\begin{aligned}\n",
    "&1.\\quad \\underset{\\mu, \\sigma^2}{\\mathrm{argmax}}\\; \\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log \\mathcal{N}(y_n; \\mu_k, \\sigma^2_k)\\\\\n",
    "&2.\\quad \\underset{\\pi}{\\mathrm{argmax}}\\; \\sum_{n=1}^N \\sum_{k=1}^K r_{n, k}\\pi_k\n",
    "\\end{aligned}\n",
    "We can solve each optimization problem analytically by finding stationary points of the gradient (or the Lagrangian):\n",
    "- $\\mu_{\\text{new}} = \\frac{1}{ \\sum_{n=1}^N r_{n, k}} \\sum_{n=1}^N r_{n, k} y_n$\n",
    "\n",
    "- $\\sigma^2_{\\text{new}} = \\frac{1}{ \\sum_{n=1}^N r_{n, k}} \\sum_{n=1}^N r_{n, k} (y_n - \\mu_{\\text{new}})^2$\n",
    "\n",
    "- $\\pi_{\\text{new}} =  \\frac{\\sum_{n=1}^N r_{n, k}}{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: EM for the Gaussian Mixture Model of Birth Weight\n",
    "### All Together\n",
    "\n",
    "**Initialization:**\n",
    "Pick any $\\pi$, $\\mu$, $\\sigma^2$\n",
    "\n",
    "**E-Step:**\n",
    "Compute $r_{n, k} = \\displaystyle\\frac{\\pi_{k, \\text{old}}\\,\\mathcal{N}(y_n; \\mu_{k, \\text{old}}, \\sigma^2_{k, \\text{old}})}{\\mathcal{Z}}$, where $\\mathcal{Z} = \\sum_{k=1}^K \\pi_{k, \\text{old}}\\,\\mathcal{N}(y_n; \\mu_{k, \\text{old}}, \\sigma^2_{k, \\text{old}})$.\n",
    "\n",
    "**M-Step:**\n",
    "Compute model parameters:\n",
    "- $\\mu_{\\text{new}} = \\frac{1}{ \\sum_{n=1}^N r_{n, k}} \\sum_{n=1}^N r_{n, k} y_n$\n",
    "\n",
    "- $\\sigma^2_{\\text{new}} = \\frac{1}{ \\sum_{n=1}^N r_{n, k}} \\sum_{n=1}^N r_{n, k} (y_n - \\mu_{\\text{new}})^2$\n",
    "\n",
    "- $\\pi_{\\text{new}} =  \\frac{\\sum_{n=1}^N r_{n, k}}{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing EM for the Gaussian Mixture Model of Birth Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2920267342544727 1.5260468747347409 0.4291651611436793\n",
      "5.4199527046935135e-06 7.163537707115768e-06 3.7030642797622287e-06\n",
      "4.847421726967444e-10 6.412799516536099e-10 3.313286159742346e-10\n"
     ]
    }
   ],
   "source": [
    "#Generate data\n",
    "N = 2000\n",
    "pis = [0.2, 0.6, 0.2]\n",
    "mus = [4.3, 6, 7.8]\n",
    "sigmas = [0.5**2, 0.7**2, 0.5**2]\n",
    "K = 3\n",
    "zs = np.random.choice(np.arange(K), size=N, p=pis)\n",
    "y = np.array([np.random.normal(mus[z], sigmas[z]**0.5, 1)[0] for z in zs])\n",
    "\n",
    "#initialization\n",
    "mu_init = [2, 4, 5]\n",
    "sigma_init = [2., 2., 2.]\n",
    "pi_init = [0.33, 0.33, 0.33]\n",
    "\n",
    "#implement EM\n",
    "mu_current = mu_init\n",
    "sigma_current = sigma_init\n",
    "pi_current = pi_init\n",
    "\n",
    "total_iter = 1500\n",
    "\n",
    "for i in range(total_iter):\n",
    "    #E-step\n",
    "    r_unnormalized = np.array([(pi_current[k] *  sp.stats.norm(mu_current[k], sigma_current[k]**0.5).pdf(y)) for k in range(K)]).T\n",
    "    r = r_unnormalized / r_unnormalized.sum(axis=1).reshape((-1, 1))\n",
    "    #M-step\n",
    "    mu_next = np.array([1. / r[:, k].sum() * (r[:, k] * y).sum() for k in range(K)])\n",
    "    sigma_next = np.array([1. / r[:, k].sum() * (r[:, k] * (y - mu_next[k])**2).sum() for k in range(K)])\n",
    "    pi_next = r.sum(axis=0) / r.shape[0]\n",
    "    \n",
    "    #convergence check\n",
    "    if i % 500 == 0:\n",
    "        print(np.linalg.norm(mu_next - mu_current), np.linalg.norm(sigma_next - sigma_current), np.linalg.norm(pi_next - pi_current))\n",
    "    \n",
    "    mu_current = mu_next\n",
    "    sigma_current = sigma_next\n",
    "    pi_current = pi_next\n",
    "    \n",
    "x = np.linspace(y.min(), y.max(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.hist(y, bins=60, density=True, color='gray', alpha=0.5, label='histogram of birth weights')\n",
    "ax.plot(x, pi_current[0] * sp.stats.norm(mu_current[0], sigma_current[0]**0.5).pdf(x), color='red', label='First Gaussian')\n",
    "ax.plot(x, pi_current[1] * sp.stats.norm(mu_current[1], sigma_current[1]**0.5).pdf(x), color='blue', label='Second Gaussian')\n",
    "ax.plot(x, pi_current[2] * sp.stats.norm(mu_current[2], sigma_current[2]**0.5).pdf(x), color='green', label='Third Gaussian')\n",
    "ax.set_title('GMM for Birth Weights')\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Example: EM for Gaussian Mixture Models (Multivariate)\n",
    "\n",
    "Recall that our Gaussian mixture model, of $K$ number of Gaussians with means $\\mu = [\\mu_1, \\ldots, \\mu_K]$ and covariances $\\Sigma = [\\Sigma_1, \\ldots, \\Sigma_K]$, is defined as:\n",
    "\n",
    "\\begin{aligned}\n",
    "Z_n &\\sim Cat(\\pi),\\\\\n",
    "Y_n &\\sim \\mathcal{N}(\\mu_{Z_n}, \\Sigma_{Z_n}),\n",
    "\\end{aligned}\n",
    "where $n=1, \\ldots, N$ and $\\sum_{k=1}^K \\pi_k = 1$. \n",
    "\n",
    "We derive the updates for $\\pi$, $\\mu$ and $\\Sigma$ for the EM algorithm\n",
    "#### E-step:\n",
    "$$\n",
    "q_{\\text{new}} = p(Z_n|y_n, \\pi_{\\text{old}}, \\mu_{\\text{old}}, \\Sigma_{\\text{old}}) = \\frac{p(y_n|Z_n, \\mu_{\\text{old}}, \\Sigma_{\\text{old}})p(Z_n|\\pi_{\\text{old}})}{\\int p(y_n|z_n, \\mu_{\\text{old}}, \\Sigma_{\\text{old}})p(z_n|\\pi_{\\text{old}}) dz_n}\n",
    "$$\n",
    "\n",
    "Since $Z_n$ is a categorical variable, we compute the probability of $Z_n = k$ separately:\n",
    "\n",
    "$$\n",
    "p(Z_n = k|y_n, \\pi_{\\text{old}}, \\mu_{\\text{old}}, \\Sigma_{\\text{old}}) = \\frac{p(y_n|Z_n = k, \\mu_{\\text{old}}, \\Sigma_{\\text{old}})p(Z_n=k | \\pi_{\\text{old}})}{\\sum_{k=1}^K p(y|Z_n = k, \\mu_{\\text{old}}, \\Sigma_{\\text{old}})p(Z_n=k | \\pi_{\\text{old}})} = \\underbrace{\\frac{\\pi_{k, \\text{old}}\\,\\mathcal{N}(y_n; \\mu_{k, \\text{old}}, \\Sigma_{k, \\text{old}})}{\\mathcal{Z}}}_{r_{n, k}}\n",
    "$$\n",
    "\n",
    "where $\\mathcal{Z} = \\sum_{k=1}^K \\pi_{k, \\text{old}}\\,\\mathcal{N}(y_n; \\mu_{k, \\text{old}}, \\Sigma_{k, \\text{old}})$.\n",
    "\n",
    "Thus, $q_{\\text{new}}(Z_n)$ is a categorical distribution $Cat([r_{n, 1}, \\ldots, r_{n, K}])$.\n",
    "\n",
    "#### M-Step:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mu_{\\text{new}}, \\Sigma_{\\text{new}}, \\pi_{\\text{new}} &= \\underset{\\mu, \\Sigma, \\pi}{\\mathrm{argmax}}\\, \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim p(Z_n|Y_n, \\mu_{\\text{old}}, \\Sigma_{\\text{old}}, \\pi_{\\text{old}})}\\left[\\log \\left( p(y_n, Z_n | \\mu, \\sigma \\right) \\right]\\\\\n",
    "&= \\underset{\\mu, \\Sigma, \\pi}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\left[\\log p(y_n | Z_n=k, \\mu, \\Sigma)  + \\log p(Z_n=k | \\pi)\\right]\\\\\n",
    "&= \\underset{\\mu, \\Sigma}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log p(y_n | Z_n=k, \\mu, \\Sigma)  + \\underset{\\pi}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log p(Z_n=k | \\pi)\\\\\n",
    "&=\\underset{\\mu, \\Sigma}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log \\mathcal{N}(y_n; \\mu_{k}, \\Sigma_{k})  + \\underset{\\pi}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log \\pi_k\n",
    "\\end{aligned}\n",
    "where $n=1, \\ldots, N$ and $\\sum_{k=1}^K \\pi_k = 1$. \n",
    "\n",
    "We solve the two optimization problems separately. The optimization problem\n",
    "\n",
    "$$\n",
    "\\underset{\\pi}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log \\pi_k,\\quad \\sum_{k=1}^K \\pi_k = 1\n",
    "$$\n",
    "\n",
    "can be solved using Lagrangian multipliers yielding the solution:\n",
    "\n",
    "$$\n",
    "\\pi_{\\text{new}, k} = \\frac{\\sum_{n=1}^N r_{n, k}}{N}\n",
    "$$\n",
    "\n",
    "The optimization problem \n",
    "\n",
    "$$\n",
    "\\underset{\\mu, \\Sigma}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log \\mathcal{N}(y_n; \\mu_{k}, \\Sigma_{k}) \n",
    "$$\n",
    "\n",
    "can be solved by taking the gradient with respect to $\\mu_k$, $\\Sigma_k$ for each $k$ and computing the stationary points of the gradient (remember to check for the global concavity to ensure you've found a global max). Doing so gives us the optimal points\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mu_{\\text{new},k} &= \\frac{1}{\\sum_{n=1}^N r_{n, k}} \\sum_{n=1}^N r_{n,k}y_n, &\\quad (\\text{weighted sample mean})\\\\\n",
    "\\Sigma_{\\text{new},k} &= \\frac{1}{\\sum_{n=1}^N r_{n, k}}  \\sum_{n=1}^N r_{n,k} (y_n - \\mu_{\\text{new},k})(y_n - \\mu_{\\text{new},k})^\\top, &\\quad (\\text{weighted sample covariance})\n",
    "\\end{aligned}\n",
    "\n",
    "**Exercise:** Verify that the updates for $\\pi_{\\text{new},k}, \\mu_{\\text{new},k}, \\Sigma_{\\text{new},k}$ maximizes $\\mathbb{E}_{Z_n\\sim p(Z_n|Y_n, \\mu_{\\text{old}}, \\Sigma_{\\text{old}}, \\pi_{\\text{old}})}\\left[\\log \\left( p(y_n, Z_n | \\mu, \\sigma \\right) \\right]$."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
