{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture #17: Variational Inference in Context\n",
    "## AM 207: Advanced Scientific Computing\n",
    "### Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "### Fall, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"fig/logos.jpg\" style=\"height:150px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### Import basic libraries\n",
    "import numpy\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy.stats.multivariate_normal as mvn\n",
    "import autograd.scipy.stats.norm as norm\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam\n",
    "import numpy\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "from IPython.display import HTML\n",
    "from IPython.display import YouTubeVideo\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Administrative Matters\n",
    "1. **Attendance Quiz:** \n",
    "\n",
    "2. **Optional homework:** the optional homework will be averaged with your other HW scores, total-after-drop / (11 - 1), if it helps with that average, otherwise it will not be counted towards your HW average - this means you don't need to do this HW or don't need to worry about making mistakes. <br><br>\n",
    "\n",
    "3. **Homework #9 is not optional:** Homework #9 is on models for sequential data and is not optional. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "1. Review of Automatic Differentiation\n",
    "2. How to Evaluate Approximate Inference\n",
    "3. How to Improve Approximate Inference\n",
    "4. Why do I care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review of Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation Trace and Computational Graph\n",
    "\n",
    "Given a function $f: \\mathbb{R}^n \\to \\mathbb{R}^m$, we represent $f$ as the composition of elementary functions through elemtary operations by a sequence of intermediate values $v_k$ that is involved with the evaluation of $f$, this is the ***evaluation trace***. We can also represent the trace graphically, resulting in the ***computational graph***.\n",
    "\n",
    "**Example:** Given $y = f(x_1, x_2) = \\ln(x_1) + x_1x_2 - \\sin(x_2)$, its evaluation trace and computational graph are:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"fig/trace.jpg\" style=\"height:250px;\" align=\"center\"/>\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"./fig/graph.jpg\" style=\"height: 200px;\" align=\"center\"/>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automatic Differentiation: Forward Mode\n",
    "\n",
    "In ***forward mode automatic differentiation***, we start with in the input and work towards the output: evaluating the value of each intermediate value $v_k$ as well as the derivative of $v_k$ with repect to a fixed $x_i$ using the chain rule: \n",
    "\n",
    "$$\n",
    "\\frac{\\partial v_k}{\\partial x_i} = \\sum_{v\\in \\mathrm{parent}(v_k)}\\frac{\\partial v_k}{\\partial v}\\frac{\\partial v}{\\partial x_i}\n",
    "$$\n",
    "We denote $\\frac{\\partial v_k}{x_i}$ by $\\dot{v}_k$.\n",
    "\n",
    "<img src=\"fig/forward.jpg\" style=\"height:300px;\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automatic Differentiation: Reverse Mode\n",
    "\n",
    "In ***reverse mode automatic differentiation***, we first do a forward pass to compute all intermediate values. Then we start with in the output and work towards the input: evaluating the derivative of $f$ with repect to an intermediate value $v_k$ using the chain rule: \n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial v_k} = \\sum_{v\\in \\mathrm{child}(v_k)}\\frac{\\partial f}{\\partial v}\\frac{\\partial v}{\\partial v_k}\n",
    "$$\n",
    "We denote $\\frac{\\partial f}{v_k}$ by $\\overline{v}_k$. \n",
    "\n",
    "<img src=\"fig/reverse.jpg\" style=\"height:300px;\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing Reverse Mode AutoDiff\n",
    "\n",
    "We see that each intermediate gradient computation $\\frac{\\partial f}{\\partial v_k}$ in reverse mode autodiff is local, it only requires:\n",
    "1. the current value of $v_k$\n",
    "2. the derivative of $f$ with respect to every child of $v_k$: $\\frac{\\partial f}{\\partial v},\\, v\\in \\mathrm{child}(v_k)$.\n",
    "3. the derivative of the elementary function $h_v$ describing the way $v$ depends on $v_k$.\n",
    "\n",
    "We implement the computation graph of a function $f$ as a directed graph, where each node keeps tracks of the above three pieces of information and uses them to compute its own gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An Example of Reverse Mode AutoDiff in `python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "'''small example of reverse mode autodiff as implemented in https://github.com/Rufflewind/revad/'''\n",
    "class Var:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.children = []\n",
    "        self.grad_value = None\n",
    "\n",
    "    def grad(self):\n",
    "        if self.grad_value is None:\n",
    "            self.grad_value = sum(weight * var.grad()\n",
    "                                  for weight, var in self.children)\n",
    "        return self.grad_value\n",
    "\n",
    "    #overloading the '+' operator\n",
    "    def __add__(self, other):\n",
    "        z = Var(self.value + other.value)\n",
    "        self.children.append((1.0, z))\n",
    "        other.children.append((1.0, z))\n",
    "        return z\n",
    "    \n",
    "    #overloading the '-' operator\n",
    "    def __mul__(self, other):\n",
    "        z = Var(self.value * other.value)\n",
    "        self.children.append((other.value, z))\n",
    "        other.children.append((self.value, z))\n",
    "        return z\n",
    "\n",
    "def sin(x):\n",
    "    z = Var(math.sin(x.value))\n",
    "    x.children.append((math.cos(x.value), z))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of x*y + sin(x) evaluated at x=0.5, y=4.2: 2.579425538604203\n",
      "forward pass of our implementation: 2.579425538604203\n"
     ]
    }
   ],
   "source": [
    "x = Var(0.5)\n",
    "y = Var(4.2)\n",
    "z = x * y + sin(x)\n",
    "z.grad_value = 1.0\n",
    "\n",
    "print('value of x*y + sin(x) evaluated at x=0.5, y=4.2: {}\\nforward pass of our implementation: {}'.format(0.5 * 4.2 + np.sin(0.5), z.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of dz/dx = y + cos(x) evaluated at x=0.5, y=4.2: 5.077582561890373\n",
      "reverse pass of our implementation: 5.077582561890373\n"
     ]
    }
   ],
   "source": [
    "print('value of dz/dx = y + cos(x) evaluated at x=0.5, y=4.2: {}\\nreverse pass of our implementation: {}'.format(4.2 + np.cos(0.5), x.grad_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to Evaluate Approximate Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How Good is Your Variational Approximation of the True Posterior?\n",
    "\n",
    "**Question:** Why is it hard to check that the variational posterior is a good approximation of the true posterior?\n",
    "\n",
    "You can't simply visualize the true posterior, since it's 1) high dimensional, 2) intractable to sample from.\n",
    "\n",
    "**Question:** What if we computed the KL-divergence between the true posterior and the varaitional approximation?\n",
    "\n",
    "[*\"Practical Posterior Error Bounds from Variational Objectives\"*](https://arxiv.org/abs/1910.04102): Unfortunately, even when the KL-divergence between $q$ and $p$ is effectively zero, the difference between the means and variances of $q$ and $p$ can be **arbitrarily large**. That is, a small KL-divergence doesn't capture our intuition about what it means for two distributions to be similar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Alternative Posterior Evaluation Metrics\n",
    "\n",
    "In [*\"Yes, But Did It Work: Evaluating Variational Inference\"*](https://arxiv.org/abs/1802.02538), the authors proposes two alternative posterior evaluation metrics:\n",
    "\n",
    "**1. The Pareto Smoothed Importance Sampling Diagnostic**: If the variational approximation $q$ is very different than $p$, then the importance sampling MC estimate of $\\mathbb{E}_{p(\\theta|\\text{Data})}\\left[ f(\\theta) \\right]$,\n",
    "$$\n",
    "\\mathbb{E}_{p(\\theta|\\text{Data})}\\left[ f(\\theta) \\right] \\approx \\frac{1}{S}\\sum_{s=1}^S \\frac{p(\\theta|\\text{Data})}{q(\\theta)} f(\\theta_s),\\; \\theta_s \\sim q(\\theta)\n",
    "$$\n",
    "will have very high variance, due to the fact that the importance weights $\\frac{p(\\theta|\\text{Data})}{q(\\theta)}$ will be very heterogeneous. Thus, methods of smoothing the weights, like ***Pareto Smoothed Importance Sampling (PSIS)*** will have poor performance. The efficacy of PSIS can be used as a diagnostic tool for testing if $q$ is similar to $p$.\n",
    "\n",
    "**2. The Variational Simulation-Based Calibration (VSBC) Diagnostic**: Given a Bayesian model $p(y, \\theta) = p(y|\\theta) p(\\theta)$, if your variational inference proceedure is good at approximating the posterior $p(\\theta|y)$ then it should do well for most sets of data that is generated from the model $p(y, \\theta)$.\n",
    "\n",
    "We generate $M$ sets of synthetic data from $p(y, \\theta)$. For each set of the data we approximate the posterior $q_m(\\theta)$. We then perform a calibration test on each variational approximation. This will reveal if your variational inference procedure is biased - produces approximation that are consistently flawed in some specific way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to Improve Approximate Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Your Variational Approximation Sucks, Can You Fix It?\n",
    "\n",
    "The current research on improving variational inference can be categorize by which **design choice** each work tries to improve:\n",
    "\n",
    "**1. Choice of Divergence:** In Lab #5, you explored the draw-backs of fitting an approximate posterior $q$ to the true posterior $p$ using KL-divergence. There are a huge number of works that explore performing variational inference using other types of divergences, for example: <br>\n",
    "$\\quad$ **a.** [*\"Black-box $\\alpha$-divergence Minimization\"*](https://arxiv.org/abs/1511.03243)<br>\n",
    "$\\quad$ **b.** [*\"Stein Variational Gradient Descent\"*](https://arxiv.org/abs/1608.04471)\n",
    "\n",
    "**2. Choice of Variational Family:** In Homework #0, you've seen that even for a simple Bayesian linear regression model, the model parameters were corrlated in the posterior. In Lab #7, you've seen that minimizing the KL-divergence to fit an isotropic Gaussian means that you can only capture one mode in the posterior. There are a huge number of works that explore using different types of variational families:<br>\n",
    "$\\quad$ **a.** [*\"Variational Inference with Normalizing Flows\"*](https://arxiv.org/abs/1505.05770)<br>\n",
    "$\\quad$ **b.** [*\"The Variational Gaussian Process\"*](https://arxiv.org/abs/1511.06499)<br>\n",
    "\n",
    "**3. Choice of Optimization Procedure:** Even if your divergence measure and variational family are well-chosen, the optimization objective can still be non-convex! This means that your optimization procedure might return a $q$ that is a only local-optimum. There are a large number of works that address how to jump out of local optima using SGD and some works that specifically address the optimization challenges of variational inference:<br>\n",
    "$\\quad$ **a.** [*\"Proximity Variational Inference\"*](https://arxiv.org/abs/1705.08931)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Are There Any Good Properties of Variational Approximations that We Are Sure About?\n",
    "\n",
    "In [*\"Frequentist Consistency of Variational Bayes\"*](https://arxiv.org/abs/1705.03439), the authors prove that under **certain assumptions** on $p(\\theta)$ and $p(y|\\theta)$:\n",
    "1.  as the number of observation increases, the variational approximation converges (in Total Variation distance) to the $q$ that minimizes the KL-divergence to a normal distribution centered at the ground truth parameters $\\theta_{\\text{true}}$ that generated the data.<br><br>\n",
    "2. the mean of the variational approximation is consistent and asymptoptically normal.\n",
    "\n",
    "Unfortunately, the assumptions required by the theorems **do not hold for neural network likelihood models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why is Inference for Neural Networks Hard?\n",
    "\n",
    "Research on the likelihoods (and hence posteriors) of neural networks are beginning to give us ways of visualizing these high-dimensional functions using low-dimensional (3D) projections. [Loss Landsacapes](https://losslandscape.com) represents some of the latest efforts at visualization:\n",
    "\n",
    "<img src=\"fig/loss.jpg\" style=\"height:400px;\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## It's Weirder Than You Can Imagine\n",
    "\n",
    "In [*\"Loss Landscape Sightseeing with Multi-Point Optimization\"*](https://arxiv.org/pdf/1910.03867.pdf), the authors show that neural network likelihoods (and thus posteriors) are so complicated that you can find a 2-D projection that can create any pattern you want:\n",
    "\n",
    "<img src=\"fig/loss2.jpg\" style=\"height:250px;\" align=\"center\"/>\n",
    "\n",
    "**The lesson**: take every low-dimensional visualization with a grain of salt (i.e. it far from accurately represents the entire landscape)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But why do I care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation of Variational Approximation for Real Down-stream Tasks\n",
    "\n",
    "In practice, you may only care about the quality of your posterior approximation in so far as it affects model performance on your down-stream task. So what do we want from our machine learning or statistical models, especially when they are used in safety, or fairness critical applications (e.g. personalized medicine, health-care resource allocation, criminal justic systems)?\n",
    "\n",
    "Most of us in the community agree that we want models that *1)* makes accurate predictions *2)* gives realistic estimates of its prective uncertainty. So that the model can be held-accountable by humans in the system. There are a number of subcomunities in ML that focus on studying the social impact of machine learning models as well as how to design models whose negative impact can be mitigated.\n",
    "\n",
    "**a.** [*\"Concrete Problems in AI Safety\"*](https://arxiv.org/pdf/1606.06565.pdf)<br>\n",
    "**b.** [*\"Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer\"*](https://papers.nips.cc/paper/7853-predict-responsibly-improving-fairness-and-accuracy-by-learning-to-defer.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predictiveness of the Variational Approximate Posterior\n",
    "\n",
    "We can check the predictiveness of our varational approximation of the posterior by sampling models from the posterior and then making predictions using these models by sampling from the likelihood. We then check that these predictions align well with observed data by:\n",
    "\n",
    "1. **Visualization:** visualizing the posterior predictive against the observed data. *This is generally impossible for high dimensional data.*<br><br>\n",
    "\n",
    "2. **Log Marginal Data Likelihood:** we compute the expected value of the log likelihood of the test data under our approximate posterior. *Log likelihood is only useful for comparing two different models, given a single model it is hard to say if a log likelihood value is \"good enough\".*<br><br>\n",
    "\n",
    "3. **Expected Mean Square Error and Accuracy:** we compute the expected MSE (for regression) or accuracy (for classification) on test data under our approximate posterior. *While these metric frames model quality in concrete task related terms, they are each misleading when the data contains outliers or imbalanced classes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quality of Variational Approximate Posterior Predictive Uncertainty\n",
    "\n",
    "We've argued in this course that good predictive uncertainty must involve an accurate assessment of both ***epistemic*** and ***aleatoric*** uncertainty. Since each type of uncertainty requires a different risk-management action in the down-stream task.\n",
    "\n",
    "<img src=\"fig/posterior_pred.jpg\" style=\"height:210px;\" align=\"center\"/>\n",
    "\n",
    "Unfortunately, there isn't a single good statistical metric for assessing the quality of the uncertainty of a model. \"Good\" epstemic uncertainty is especially hard to quantify. Rather than looking for statistical tests of uncertainty, some in the ML community advocate for assessing model uncertainty with respect to a set of benchmark down-stream tasks: [Bayesian Deep Learning Benchmarks](https://github.com/OATML/bdl-benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Does a Poor Posterior Approximation Imply a Poor Posterior Predictive?\n",
    "You've seen in HW#7 that even with an HMC sampler that is far from converged, you were able to produce posterior predictives that aligned well with the data and had good epistemic and aleatoric uncertainty. In fact, a number of works are showing that by capturing a little piece (if it is the right piece) of the true posterior of a BNN, you are able to capture most of the variation you want in the posterior predictive.\n",
    "\n",
    "In [*\"Subspace Inference for Bayesian Deep Learning\"*](https://arxiv.org/pdf/1907.07504.pdf), the authors provide toy examples where one obtains a posterior predictive distribution with good epistemic and aleatoric uncertainty by reducing a high dimensional parameter space to 2-dimensions and performing inference in the 2-dimensional subspace:\n",
    "<img src=\"fig/posterior_pred2.jpg\" style=\"height:210px;\" align=\"center\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
