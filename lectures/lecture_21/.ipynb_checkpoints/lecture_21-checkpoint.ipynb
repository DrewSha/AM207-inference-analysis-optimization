{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture #21: Learning Algorithms for HMMs\n",
    "## AM 207: Advanced Scientific Computing\n",
    "### Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "### Fall, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"fig/logos.jpg\" style=\"height:150px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### Import basic libraries\n",
    "import numpy\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy.stats.multivariate_normal as mvn\n",
    "import autograd.scipy.stats.norm as norm\n",
    "from scipy.special import logsumexp\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam\n",
    "import numpy\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "from IPython.display import HTML\n",
    "from IPython.display import YouTubeVideo\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "1. Review of Hidden Markov Models and State Space Models\n",
    "2. Inference: Smoothing\n",
    "3. Learning: Expectation Maximization\n",
    "4. Extensions of HMMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review of Hidden Markov Models and State Space Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hidden Markov Models\n",
    "\n",
    "In a ***hidden Markov model (HMM)***, we assume that the values in the underlying Markov process is latent\n",
    "$$\n",
    "X_{n+1} | X_{n} \\sim p(X_{n+1} | X_{n}) \\quad \\mathbf{(state\\; model)}\n",
    "$$\n",
    "\n",
    "and that, instead, we observe the process \n",
    "$$\n",
    "Y_n | X_n \\sim p(Y_n | X_n) \\quad \\mathbf{(observation\\; model)}\n",
    "$$\n",
    "\n",
    "where $p(Y_n | X_n)$ is the probability density associated with observing $Y_n \\in \\mathcal{Y}$ given the latent value, $X_n$, of the underlying Markov process at time $n$.\n",
    "\n",
    "<img src=\"fig/hmm.png\" style=\"height:150px;\" align=\"center\">\n",
    "\n",
    "If the state space is continuous, Hidden Markov Models are often called ***State-Space Models***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning and Inference for HMMs\n",
    "There are a number of inference problems associated with HMMs:\n",
    "\n",
    "**1. Learning** - learning the dynamics of the state or observation model <br><br>\n",
    "**2. Inference** - estimating the probability distribution over one or more of the latent variables, $\\{X_n\\}_{n\\geq 1}$, given a sequence of observations, $\\{Y_n\\}_{n\\geq 1}$:<br><br>\n",
    "$\\quad$**I. Filtering:** computing $p(X_n| Y_{1:n})$.<br>\n",
    "$\\quad\\quad$**a. Kalman filters** - assumes linear Gaussian model.<br>\n",
    "$\\quad\\quad$**b. Extendend Kalman filters** - assumes Gaussian noise and non-linear deterministic dynamics; approximates non-linear dynamics with 1st order Taylor approximation and apply Kamlan filter.<br>\n",
    "$\\quad\\quad$**c. Particle Filters/Sequential Monte Carlo** - approximates $p(X_n| Y_{1:n})$ with samples, these samples are iteratively adjusted to be better approximations.<br><br>\n",
    "$\\quad$**II. Smoothing:** computing $p(X_t| Y_{1:n})$ where $t < n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inference: Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recursive Algorithm for Computing $p(X_{t} | Y_{1:n})$\n",
    "\n",
    "If we assume a **linear Gaussian model**, we can **recursively** compute $p(X_{t} | Y_{1:n})$.\n",
    "\n",
    "1. Compute $p(X_{n} | Y_{1:n}) = \\mathcal{N}(\\hat{x}_{n|n}, \\hat{\\sigma}^2_{n|n})$ for each $n$ using a Kalman filter.<br><br>\n",
    "2. Compute $p(X_{n + 1} | Y_{1:n}) = \\mathcal{N}(\\hat{x}_{n+1|n}, \\hat{\\sigma}^2_{n+1|n})$ for each $n$ using a Kalman filter.<br><br>\n",
    "3. (**Induction Hypothesis**) Suppose that $p(X_{t+1} | Y_{1:n}) = \\mathcal{N}(\\hat{x}_{t+1|n} \\hat{\\sigma}^2_{t+1|n})$.<br><br>\n",
    "4. (**Update**) using the induction hypothesis, we first compute the conditional $p(X_{t} | X_{t+1}, Y_{1:n}) = \\mathcal{N}(m, s^2)$, then we integrate out $X_{t+1}$ to get:\n",
    "\n",
    "$$\n",
    "p(X_{t} | Y_{1:n}) = \\mathcal{N}(\\hat{x}_{t|n} \\hat{\\sigma}^2_{t|n})\n",
    "$$\n",
    "\n",
    "This suggests a **recursive** algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rauch-Tung-Striebel (RTS) Smoother\n",
    "\n",
    "The ***Rauch-Tung-Striebel (RTS) Smoother*** computes $p(X_{t} | Y_{1:n})$ for each $n$ in two passes:\n",
    "\n",
    "1. **(Forward pass)** Compute $p(X_{n} | Y_{1:n})$, $p(X_{n + 1} | Y_{1:n})$ using a Kalman filter<br><br>\n",
    "\n",
    "2. **(Backwards pass)** Compute $p(X_{t} | X_{t+1}, Y_{1:n})$ and then $p(X_{t} | Y_{1:n})$.\n",
    "\n",
    "See full derivations:\n",
    "1. [A Tutorial on Particle Filtering and Smoothing: Fifteen years later](https://www.seas.harvard.edu/courses/cs281/papers/doucet-johansen.pdf)\n",
    "2. [Notes on Linear Gaussian State Space Model](https://web.stanford.edu/~lmackey/stats306b/doc/stats306b-spring14-lecture11_scribed.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning: Expectation Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Maximum Likelihood Estimate of the Dynamics\n",
    "Given an HMM model, \n",
    "\\begin{align}\n",
    "X_{n+1} | X_{n} &\\sim p(X_{n+1} | X_{n}) \\quad \\mathbf{(state\\; model)}\\\\\n",
    "Y_n | X_n &\\sim p(Y_n | X_n) \\quad \\mathbf{(observation\\; model)}\n",
    "\\end{align}\n",
    "\n",
    "Suppose that $p(X_{n+1} | X_{n}) = f_\\theta(X_{n}, \\epsilon)$ and $p(Y_n | X_n) = g_\\phi(X_{n}, \\xi)$ where $f$, $g$ are functions with parameters $\\theta, \\phi$ and $\\epsilon$ and $\\xi$ are noise variables. The learning task for HMMs is to learn values for $\\theta, \\phi$. We do this by maximizing the observed data log-likelihood:\n",
    "\n",
    "$$\n",
    "\\theta_{\\text{MLE}}, \\phi_{\\text{MLE}} = \\mathrm{argmax}_{\\theta, \\phi}\\log p(Y_{1:n}; \\theta, \\phi)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Expectation Maximization for Linear Gaussian Models\n",
    "\n",
    "Typically, we maximize the observed data log-likelihood indirectly by maximizing a lower bound, the ELBO, via **expectation maximization**. For linear Gaussian models, both the E-step and the M-step have analytical solutions.\n",
    "\n",
    "1. **(E-step)** set $q(X_{1:n}) = p(X_{1:n} | Y_{1:n}; \\theta^*, \\phi^*)$, where $\\theta^*, \\phi^*$ is from the previous M-step and the posterior $p(X_{1:n} | Y_{1:n}; \\theta^*, \\phi^*)$ is computed from distributions obtained by smoothing and filtering.<br><br>\n",
    "\n",
    "2. **(M-step)** maximize the ELBO with respect to $\\theta$ and $\\phi$, using the $q$ obtained from the E-step. Since all the distributions are Gaussians, this can be done analytically.\n",
    "\n",
    "See full derivations:\n",
    "1. [Notes on Linear Gaussian State Space Model](https://web.stanford.edu/~lmackey/stats306b/doc/stats306b-spring14-lecture11_scribed.pdf)\n",
    "2. [Parameter Estimation for Linear Dynamical Systems](http://mlg.eng.cam.ac.uk/zoubin/course04/tr-96-2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Non-identifiability\n",
    "Given an HMM model, \n",
    "\\begin{align}\n",
    "X_{n+1} | X_{n} &= f_\\theta(X_{n}, \\epsilon) \\quad \\mathbf{(state\\; model)}\\\\\n",
    "Y_n | X_n &\\sim g_\\phi(X_{n}, \\xi) \\quad \\mathbf{(observation\\; model)}\n",
    "\\end{align}\n",
    "\n",
    "Given observations $1\\ldots N$ can we recover $\\theta$ and $\\phi$ through maximum likelihood, i.e. is it true that \n",
    "$$\n",
    "\\theta_{\\text{MLE}} = \\theta,\\;\\; \\phi_{\\text{MLE}} = \\phi.\n",
    "$$\n",
    "\n",
    "The answer is **no** for most models -- that is, the dynamics of the data-generating model is ***non-identifiable***. \n",
    "\n",
    "For linear Guassian models and discrete state space HMMs, we can impose a sufficient number of conditions on $f_\\theta$, $g_\\phi$ and the observations $Y_n$ to ensure that the dynamics are **identifiable**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extensions of HMMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generaling Modeling HMMs Assumptions\n",
    "Given an HMM model, \n",
    "\\begin{align}\n",
    "X_{n+1} | X_{n} &\\sim p(X_{n+1} | X_{n}) \\quad \\mathbf{(state\\; model)}\\\\\n",
    "Y_n | X_n &\\sim p(Y_n | X_n) \\quad \\mathbf{(observation\\; model)}\n",
    "\\end{align}\n",
    "we can consider the following:\n",
    "1. **(Non-linearity, non-Gaussianity)** $p(X_{n+1} | X_{n}) = f(X_{n}, \\epsilon)$ and $p(Y_n | X_n) = g(X_{n}, \\xi)$ where $f$, $g$ are non-linear functions and $\\epsilon$ and $\\xi$ are noise variables.<br><br>\n",
    "2. **(Time-varying dynamics)** $p(X_{n+1} | X_{n}) = f(X_{n}, n, \\epsilon)$ and $p(Y_n | X_n) = g(X_{n}, n, \\xi)$. That is the state and observation dyanmics change over time.<br><br>\n",
    "3. **(Continuous time)** describing the state and observation dynamics as instantaneous change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why Continuous Time HMMs?\n",
    "\n",
    "In many domains, sequential data are irregularly sampled with uneven amounts of time between samples. Processing multiple sources of data into a single multivariate observation $Y_n$ often introduces errors and can bias the learning/inference.\n",
    "<img src=\"fig/irregular.png\" style=\"height:350px;\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Ordinary Differential Equations\n",
    "Assume that observations $x$ are generated by latent states $z$ and that the latent dynamics is given by the **ordinary differential equation (ODE)**\n",
    "$$ \n",
    "\\frac{dz}{dt} = f_\\theta(z(t))\n",
    "$$\n",
    "where $f$ is a neural network with parameters $\\theta$.\n",
    "Then, $z_1 = z_0 + \\int_{t_0}^{t_1} f_\\theta(z(t)) dt$; this can be computed by a call to a black-box ODE solver.\n",
    "\n",
    "We assume the following generative model for the data:\n",
    "<img src=\"fig/gen_model.png\" style=\"height:150px;\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural ODE's for Continuous HMM\n",
    "To learn the dynamics, i.e. find $\\theta_{\\text{MLE}}$, we use a **variational autoencoder** (i.e. we perform expectation maximization with the E-step computed using variationl inference and amortization):\n",
    "<img src=\"fig/algo2.png\" style=\"height:250px;\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training Neural ODE's \n",
    "Given any loss function $L$ of $z_1$, we can compute it as:\n",
    "<img src=\"fig/loss.png\" style=\"height:60px;\" align=\"center\">\n",
    "To maximize $L$ we need the gradient $\\nabla_{\\theta}L$. Rather than back-propagating thru a black-box ODE solver, we can turn the computation of $\\nabla_{\\theta}L$ into two additional ODE problems:\n",
    "\n",
    "1. we show that $\\frac{\\partial L}{\\partial z} = a(t)$ where \n",
    "$$\\frac{da}{dt} = -a(t)^\\top \\frac{\\partial f(z(t), t, \\theta)}{\\partial z}.$$\n",
    "2. we show that \n",
    "$$\\frac{\\partial L}{\\partial \\theta} = - \\int_{t_0}^{t_1} a(t)^\\top\\frac{\\partial f(z(t), t, \\theta)}{\\partial \\theta}.$$\n",
    "\n",
    "**Both derivatives in the above can be computed by calls to the ODE solver.**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
